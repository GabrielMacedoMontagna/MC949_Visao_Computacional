{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2c2d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219143e2",
   "metadata": {},
   "source": [
    "## Funções Auxiliares (Carregamento, Salvamento e Visualização)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19d37d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def desserializar_keypoints(arr: np.ndarray) -> List[cv2.KeyPoint]:\n",
    "    \"\"\"\n",
    "    Reconstrói lista de cv2.KeyPoint a partir do array (N,7).\n",
    "    \"\"\"\n",
    "    kps = []\n",
    "    for row in arr:\n",
    "        k = cv2.KeyPoint(\n",
    "            x=float(row[0]), y=float(row[1]), size=float(row[2]),\n",
    "            angle=float(row[3]), response=float(row[4]),\n",
    "            octave=int(row[5]), class_id=int(row[6])\n",
    "        )\n",
    "        kps.append(k)\n",
    "    return kps\n",
    "\n",
    "\n",
    "def carregar_features_npz(caminho_npz: str) -> Tuple[List[cv2.KeyPoint], np.ndarray, str]:\n",
    "    \"\"\"\n",
    "    Lê um .npz salvo pela Etapa 2 e retorna (keypoints, descriptors, imagem_absoluta).\n",
    "    \"\"\"\n",
    "    with np.load(caminho_npz, allow_pickle=True) as data:\n",
    "        kps = desserializar_keypoints(data[\"keypoints\"])\n",
    "        desc = data[\"descriptors\"]\n",
    "        img_path = str(data[\"imagem_absoluta\"])\n",
    "    return kps, desc, img_path\n",
    "\n",
    "\n",
    "def carregar_matches_npz(caminho_npz) -> List[cv2.DMatch]:\n",
    "    \"\"\"\n",
    "    Carrega os matches salvos em .npz e restaura cada linha como um objeto cv2.DMatch.\n",
    "    Retorna uma lista de cv2.DMatch.\n",
    "    \"\"\"\n",
    "\n",
    "    with np.load(caminho_npz, allow_pickle=True) as data:\n",
    "        arr = data[\"matches\"]  # array shape (N, 3)\n",
    "        matches = []\n",
    "        for row in arr:\n",
    "            # cv2.DMatch(queryIdx, trainIdx, distance)\n",
    "            m = cv2.DMatch(_queryIdx=int(row[0]), _trainIdx=int(row[1]), _distance=float(row[2]))\n",
    "            matches.append(m)\n",
    "    return matches\n",
    "\n",
    "\n",
    "def calcular_homogr(kps1, kps2, matches, params = None, direction = '2to1'):\n",
    "    \"\"\"\n",
    "    Calcula a homografia entre duas imagens usando os pontos correspondentes.\n",
    "    \"\"\"\n",
    "    if not kps1 or not kps2 or not matches or len(matches) < 4:\n",
    "        return None, None\n",
    "\n",
    "    # Extrai os pontos-chave e descritores\n",
    "    pts1 = [kps1[m.queryIdx].pt for m in matches]\n",
    "    pts2 = [kps2[m.trainIdx].pt for m in matches]\n",
    "\n",
    "    src, dst = (pts2, pts1) if direction == \"2to1\" else (pts1, pts2)\n",
    "\n",
    "    # Calcula a homografia usando RANSAC\n",
    "    H, mask = cv2.findHomography(np\n",
    "                                 .array(src, dtype=np.float32), np.array(dst, dtype=np.float32), cv2.RANSAC, **(params or {}))\n",
    "\n",
    "    return H, mask\n",
    "\n",
    "def alinhar_imgs(img1, img2, homografia):\n",
    "    if homografia is None:\n",
    "        return None\n",
    "    \n",
    "    h1, w1 = img1.shape[:2]\n",
    "    h2, w2 = img2.shape[:2]\n",
    "\n",
    "    # Cantos da imagem 2\n",
    "    cantos2 = np.array([[0,0],[w2,0],[w2,h2],[0,h2]], dtype=np.float32).reshape(-1,1,2)\n",
    "\n",
    "    # Aplica a homografia nos cantos da imagem 2\n",
    "    cantos2_trans = cv2.perspectiveTransform(cantos2, homografia)\n",
    "\n",
    "    # Combina com os cantos da imagem 1 para calcular o retangulo final\n",
    "    cantos_totais = np.vstack((cantos2_trans, np.array([[0,0],[w1,0],[w1,h1],[0,h1]], dtype=np.float32).reshape(-1,1,2)))\n",
    "    xmin, ymin = np.floor(cantos_totais.min(axis=0).ravel()).astype(np.int32)\n",
    "    xmax, ymax = np.ceil(cantos_totais.max(axis=0).ravel()).astype(np.int32)\n",
    "\n",
    "    # Translacao para coordenadas positivas\n",
    "    translacao = [-xmin, -ymin]\n",
    "    T = np.array([[1,0,translacao[0]], [0,1,translacao[1]], [0,0,1]], dtype=np.float64)\n",
    "\n",
    "    # Aplica warpPerspective com a homografia ajustada\n",
    "    res = cv2.warpPerspective(img2, T @ homografia, (xmax - xmin, ymax - ymin))\n",
    "\n",
    "    # Coloca img1 na posição correta\n",
    "    res[translacao[1]:translacao[1]+h1, translacao[0]:translacao[0]+w1] = img1\n",
    "\n",
    "    return res\n",
    "\n",
    "def salvar_homogr_npz(dir_saida, i, j, H, mask, path1, path2, metrics, params=None, direction=\"2to1\"):\n",
    "    os.makedirs(dir_saida, exist_ok=True)\n",
    "    mask_arr = np.asarray(mask, dtype=np.uint8).reshape(-1,1) if mask is not None else np.zeros((0,1), np.uint8)\n",
    "    np.savez_compressed(\n",
    "        os.path.join(dir_saida, f\"homogr_{i:03d}_{j:03d}.npz\"),\n",
    "        H=np.asarray(H, dtype=np.float32) if H is not None else np.zeros((3,3), np.float32),\n",
    "        mask=mask_arr,\n",
    "        inliers=np.int32(metrics.get(\"inliers\", 0)),\n",
    "        total=np.int32(metrics.get(\"total\", 0)),\n",
    "        rmse_px=np.float32(metrics.get(\"rmse_px\") if metrics.get(\"rmse_px\") is not None else np.nan),\n",
    "        direction=str(direction),                 # \"2to1\" => img2 -> img1\n",
    "        params_json=json.dumps(params or {}),     # p/ reprodutibilidade\n",
    "        idx_i=np.int32(i), idx_j=np.int32(j),\n",
    "        path_i=str(path1), path_j=str(path2)\n",
    "    )\n",
    "\n",
    "def carregar_homogr_npz(caminho_npz):\n",
    "    \"\"\"\n",
    "    Lê homogr_*.npz e retorna:\n",
    "      H (3x3 float32), mask (Nx1 uint8), meta (dict: inliers, total, rmse_px, direction, params_json, idx_i, idx_j, path_i, path_j)\n",
    "    \"\"\"\n",
    "    with np.load(caminho_npz, allow_pickle=True) as d:\n",
    "        H = d[\"H\"].astype(np.float32)\n",
    "        mask = d[\"mask\"].astype(np.uint8)\n",
    "        meta = {\n",
    "            \"inliers\": int(d[\"inliers\"]),\n",
    "            \"total\": int(d[\"total\"]),\n",
    "            \"rmse_px\": None if np.isnan(d[\"rmse_px\"]) else float(d[\"rmse_px\"]),\n",
    "            \"direction\": str(d[\"direction\"]),\n",
    "            \"params_json\": str(d[\"params_json\"]),\n",
    "            \"idx_i\": int(d[\"idx_i\"]), \"idx_j\": int(d[\"idx_j\"]),\n",
    "            \"path_i\": str(d[\"path_i\"]), \"path_j\": str(d[\"path_j\"]),\n",
    "        }\n",
    "    return H, mask, meta\n",
    "\n",
    "def carregar_homogr_dir(dir_homogr):\n",
    "    arquivos = sorted(glob.glob(os.path.join(dir_homogr, \"homogr_*.npz\")))\n",
    "    dados = []\n",
    "    for f in arquivos:\n",
    "        H, mask, meta = carregar_homogr_npz(f)\n",
    "        dados.append((H, mask, meta, f))\n",
    "    return dados  # lista de tuplas (H, mask, meta, caminho)\n",
    "\n",
    "def _rmse_reproj(H, pts_src, pts_dst, mask):\n",
    "    if H is None or mask is None or not mask.any():\n",
    "        return None\n",
    "    sel = mask.ravel().astype(bool)\n",
    "    if sel.sum() < 4:\n",
    "        return None\n",
    "    src = np.float32(pts_src)[sel]  # pts_src no sistema da imagem de origem em H\n",
    "    dst = np.float32(pts_dst)[sel]  # pts_dst no sistema de destino\n",
    "    src_h = cv2.convertPointsToHomogeneous(src).reshape(-1,3).T\n",
    "    proj = (H @ src_h); proj = (proj[:2] / proj[2]).T\n",
    "    dif = dst - proj\n",
    "    return float(np.sqrt((dif**2).sum(axis=1).mean()))\n",
    "\n",
    "def listar_pares_de_matches(caminho_matcher_dir, only_sequential: bool = True, n_imgs: int | None = None):\n",
    "     \"\"\"\n",
    "     Lê os arquivos matches_*.npz e retorna:\n",
    "       - only_sequential=True: apenas pares sequenciais com wrap (i, (i+1)%n)\n",
    "       - only_sequential=False: todos os pares encontrados\n",
    "     Se n_imgs não for passado, tenta inferir n a partir dos índices observados.\n",
    "     \"\"\"\n",
    "     arquivos = sorted(glob.glob(os.path.join(caminho_matcher_dir, \"matches_*.npz\")))\n",
    "     parsed = []\n",
    "     for arq in arquivos:\n",
    "         base = os.path.splitext(os.path.basename(arq))[0]  # matches_000_001\n",
    "         _, si, sj = base.split(\"_\")\n",
    "         parsed.append((int(si), int(sj), arq))\n",
    " \n",
    "     if not only_sequential:\n",
    "         return parsed\n",
    " \n",
    "     # Filtra para pares sequenciais com wrap\n",
    "     if n_imgs is None:\n",
    "         idxs = set()\n",
    "         for i, j, _ in parsed:\n",
    "             idxs.add(i); idxs.add(j)\n",
    "         n = max(idxs) + 1 if idxs else 0\n",
    "     else:\n",
    "         n = int(n_imgs)\n",
    " \n",
    "     seq = {(i, (i + 1) % n) for i in range(n)}\n",
    "     filtered = [t for t in parsed if (t[0], t[1]) in seq]\n",
    "     # Ordenação estável por (i, j) ajuda na leitura/depuração\n",
    "     filtered.sort(key=lambda t: (t[0], t[1]))\n",
    "     return filtered\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1b6a00",
   "metadata": {},
   "source": [
    "## Pipeline Principal da Etapa 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff561d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisar_homogr_alinhamento(caminho_base_etapa2: str, caminho_base_etapa3: str, detectores: List[str], matchers: List[str], candidatos: List[dict] | None = None, sequential_pairs: bool = True):\n",
    "    \"\"\"\n",
    "    Pipeline da Etapa 4: Carrega features e matches, calcula homografia com RANSAC e alinha imagens com warpPerspective.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*65}\\nHomografia e alinhamento para o conjunto: '{os.path.basename(caminho_base_etapa3)}'\\n{'='*65}\")\n",
    "\n",
    "    # Carrega a ordem das imagens\n",
    "    caminho_json = os.path.join(caminho_base_etapa2, \"ordem_imagens.json\")\n",
    "    try:\n",
    "        with open(caminho_json, \"r\") as f:\n",
    "            arquivos_de_imagem_abs = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[Erro] 'ordem_imagens.json' não encontrado em '{caminho_base_etapa2}'. Abortando.\")\n",
    "        return\n",
    "    \n",
    "    # Itera sobre os detectores (sift, orb, etc.)\n",
    "    for nome_detector in detectores:\n",
    "        print(f\"\\n--- Detector: {nome_detector.upper()} ---\")\n",
    "        caminho_detector = os.path.join(caminho_base_etapa2, nome_detector)\n",
    "        arquivos_feature_npz = sorted(glob.glob(os.path.join(caminho_detector, \"*_features.npz\")))\n",
    "        if len(arquivos_feature_npz) < 2:\n",
    "            continue\n",
    "\n",
    "        # Itera sobre os matchers (bf, flann)\n",
    "        for nome_matcher in matchers:\n",
    "            print(f\"  - Matcher: {nome_matcher.upper()}\")\n",
    "            caminho_matcher = os.path.join(caminho_base_etapa3, nome_detector, nome_matcher)\n",
    "\n",
    "            # Cria o diretório de saída para esta combinação\n",
    "            dir_saida = os.path.join(\"resultados_etapa4\", os.path.basename(caminho_base_etapa3), nome_detector, nome_matcher)\n",
    "            os.makedirs(dir_saida, exist_ok=True)\n",
    "            # NEW: processa todos os pares disponíveis na Etapa 3 (sequenciais ou todas combinações)\n",
    "            pares = listar_pares_de_matches(caminho_matcher, only_sequential=sequential_pairs)\n",
    "            if not pares:\n",
    "                print(\"    [Aviso] Nenhum matches_*.npz encontrado.\")\n",
    "                continue\n",
    "\n",
    "            for (i, j, caminho_npz_matches) in pares:\n",
    "                # Carrega features/paths das imagens i, j\n",
    "                kps1, desc1, path1 = carregar_features_npz(arquivos_feature_npz[i])\n",
    "                kps2, desc2, path2 = carregar_features_npz(arquivos_feature_npz[j])\n",
    "                img1 = cv2.imread(path1); img2 = cv2.imread(path2)\n",
    "\n",
    "                # Carrega matches do par\n",
    "                match_data = carregar_matches_npz(caminho_npz_matches)\n",
    "                if not kps1 or not kps2 or not match_data:\n",
    "                    salvar_homogr_npz(dir_saida, i, j, None, None, path1, path2,\n",
    "                                      metrics={\"inliers\":0,\"total\":0,\"rmse_px\":None},\n",
    "                                      params=None, direction=\"2to1\")\n",
    "                    continue\n",
    "\n",
    "                # Calcula H_21 (img2 -> img1) e mask (reaproveita sua calcular_homogr)\n",
    "                ransac_params = {}\n",
    "                for p in candidatos or [{}]:\n",
    "                    homografia, mask = calcular_homogr(kps1, kps2, match_data, p, '2to1')\n",
    "                    if homografia is not None and mask is not None and int(mask.sum()) >= 4:\n",
    "                        ransac_params = p\n",
    "                        break # Encontrou uma homografia\n",
    "\n",
    "                # Métricas úteis\n",
    "                pts1 = [kps1[m.queryIdx].pt for m in match_data]  # destino (img1)\n",
    "                pts2 = [kps2[m.trainIdx].pt for m in match_data]  # origem  (img2)\n",
    "                inliers = int(mask.sum()) if (mask is not None) else 0\n",
    "                total   = int(len(match_data))\n",
    "                rmse    = _rmse_reproj(homografia, pts2, pts1, mask)\n",
    "\n",
    "                # Salva para uso posterior (Etapa 5)\n",
    "                salvar_homogr_npz(dir_saida, i, j, homografia, mask, path1, path2,\n",
    "                                  metrics={\"inliers\":inliers,\"total\":total,\"rmse_px\":rmse},\n",
    "                                  params=ransac_params, direction=\"2to1\")\n",
    "\n",
    "                # (Opcional) Preview rápido para alguns pares\n",
    "                if (i, j) in [(0, 1), (1, 2)] and homografia is not None and img1 is not None and img2 is not None:\n",
    "                    alinhado = alinhar_imgs(img1, img2, homografia)\n",
    "                    if alinhado is not None:\n",
    "                        plt.figure(figsize=(20, 10))\n",
    "                        plt.imshow(cv2.cvtColor(alinhado, cv2.COLOR_BGR2RGB))\n",
    "                        plt.axis('off'); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9415e9",
   "metadata": {},
   "source": [
    "## Execução do Pipeline para os Conjuntos de Imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8704cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAIZ_ETAPA2 = \"resultados_etapa2\"\n",
    "RAIZ_ETAPA3 = \"resultados_etapa3\"\n",
    "DETECTORS = ['sift', 'orb', 'akaze']\n",
    "MATCHERS = ['bf', 'flann']\n",
    "\n",
    "conjuntos = [d for d in os.listdir(RAIZ_ETAPA2) if os.path.isdir(os.path.join(RAIZ_ETAPA2, d))]\n",
    "\n",
    "candidatos = [ #Parâmetros do RANSAC em grau decrescente de rigor. Se o atual não gerar um homografia válida, tenta o próximo. Tudo fica salvo no .npz\n",
    "    {\"ransacReprojThreshold\": 0.75, \"confidence\": 0.9999},\n",
    "    {\"ransacReprojThreshold\": 1.0, \"confidence\": 0.9997},\n",
    "    {\"ransacReprojThreshold\": 1.5, \"confidence\": 0.9995},\n",
    "    {}\n",
    "]\n",
    "\n",
    "for nome_conjunto in sorted(conjuntos):\n",
    "    caminho_detector = os.path.join(RAIZ_ETAPA2, nome_conjunto)\n",
    "    caminho_matcher = os.path.join(RAIZ_ETAPA3, nome_conjunto)\n",
    "    analisar_homogr_alinhamento(caminho_detector, caminho_matcher, DETECTORS, MATCHERS, candidatos, sequential_pairs=False) #ATENÇÃO, sequential_pairs=False APENAS PARA CALCULO DO GRAFO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ed35e9",
   "metadata": {},
   "source": [
    "## Etapa bônus: identificação da ordem das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f639c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grafo inicializado com 61 vértices.\n",
      "Arestas adicionadas ao grafo: 1112\n",
      "Aresta 004 -> 000: custo (rmse) = 0.3247\n",
      "Aresta 004 -> 001: custo (rmse) = 0.3032\n",
      "Aresta 004 -> 002: custo (rmse) = 0.2783\n",
      "Aresta 004 -> 003: custo (rmse) = 0.3069\n",
      "Aresta 004 -> 005: custo (rmse) = 0.2867\n",
      "Aresta 004 -> 007: custo (rmse) = 0.2852\n",
      "Aresta 004 -> 008: custo (rmse) = 0.2814\n",
      "Aresta 004 -> 009: custo (rmse) = 0.3038\n",
      "Aresta 004 -> 010: custo (rmse) = 0.3101\n",
      "Aresta 004 -> 011: custo (rmse) = 0.2964\n",
      "Aresta 004 -> 012: custo (rmse) = 0.3414\n",
      "Aresta 004 -> 013: custo (rmse) = 0.3700\n",
      "Aresta 004 -> 014: custo (rmse) = 0.3971\n",
      "Aresta 004 -> 015: custo (rmse) = 0.3885\n",
      "Aresta 004 -> 016: custo (rmse) = 0.3534\n",
      "Aresta 004 -> 017: custo (rmse) = 0.3840\n",
      "Aresta 004 -> 018: custo (rmse) = 0.3863\n",
      "Aresta 004 -> 019: custo (rmse) = 0.3854\n",
      "Aresta 004 -> 020: custo (rmse) = 0.4240\n",
      "Aresta 004 -> 021: custo (rmse) = 0.3595\n",
      "Aresta 004 -> 022: custo (rmse) = 0.3772\n",
      "Aresta 004 -> 023: custo (rmse) = 0.3527\n",
      "Aresta 004 -> 024: custo (rmse) = 0.3070\n",
      "Aresta 004 -> 025: custo (rmse) = 0.3907\n",
      "Aresta 004 -> 026: custo (rmse) = 0.2738\n",
      "Aresta 004 -> 027: custo (rmse) = 0.3517\n",
      "Aresta 004 -> 028: custo (rmse) = 0.3358\n",
      "Aresta 004 -> 029: custo (rmse) = 0.3467\n",
      "Aresta 004 -> 030: custo (rmse) = 0.3557\n",
      "Aresta 004 -> 031: custo (rmse) = 0.3386\n",
      "Aresta 004 -> 032: custo (rmse) = 0.2847\n",
      "Aresta 004 -> 034: custo (rmse) = 0.2724\n",
      "Aresta 004 -> 036: custo (rmse) = 0.2890\n",
      "Aresta 004 -> 037: custo (rmse) = 0.3055\n",
      "Aresta 004 -> 040: custo (rmse) = 0.4175\n",
      "Caminho guloso do 000 até 060 : ['000', '002', '004', '034', '009', '037', '005', '006', '008', '010', '035', '049', '054', '026', '007', '036', '019', '045', '051', '021', '050', '020', '030', '043', '016', '017', '028', '012', '027', '014', '033', '046', '059', '048', '031', '003', '011', '042', '056', '040', '055', '041', '015', '025', '013', '029', '018', '038', '022', '023', '024', '044', '032', '047', '039', '001']\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def caminho_guloso(G, inicio, fim):\n",
    "    '''\n",
    "    Encontra um caminho do nó 'inicio' ao nó 'fim' em um grafo ponderado G usando uma abordagem gulosa.\n",
    "    Sempre escolhe o vizinho com o menor peso que ainda não foi visitado.\n",
    "    Retorna a lista de nós no caminho encontrado.\n",
    "    '''\n",
    "    caminho = [inicio]\n",
    "    atual = inicio\n",
    "    pai = None\n",
    "    visitados = set([inicio])\n",
    "    while atual != fim:\n",
    "        vizinhos = [v for v in G.neighbors(atual) if v != pai and v not in visitados]\n",
    "        if not vizinhos:\n",
    "            break\n",
    "        # Escolhe o vizinho com menor peso\n",
    "        proximo = min(vizinhos, key=lambda v: G[atual][v]['weight'])\n",
    "        caminho.append(proximo)\n",
    "        visitados.add(proximo)\n",
    "        pai, atual = atual, proximo\n",
    "    return caminho\n",
    "\n",
    "# Inicializa um grafo não direcionado\n",
    "G = nx.Graph()\n",
    "\n",
    "# Adiciona vértices numerados de 000 a 060 (inclusive)\n",
    "for i in range(61):\n",
    "    G.add_node(f\"{i:03d}\")\n",
    "\n",
    "print(f\"Grafo inicializado com {G.number_of_nodes()} vértices.\")\n",
    "\n",
    "# Diretório dos arquivos de homografia\n",
    "dir_homogr = \"resultados_etapa4/images-normal/sift/flann-20250827T130217Z-1-001/flann\"\n",
    "\n",
    "# Percorre todos os arquivos homogr_*.npz e adiciona arestas ponderadas pelo rmse (ignora rmse=0)\n",
    "for caminho_npz in sorted(glob.glob(os.path.join(dir_homogr, \"homogr_*.npz\"))):\n",
    "    with np.load(caminho_npz, allow_pickle=True) as d:\n",
    "        i = f\"{int(d['idx_i']):03d}\"\n",
    "        j = f\"{int(d['idx_j']):03d}\"\n",
    "        rmse = float(d['rmse_px']) if not np.isnan(d['rmse_px']) else None\n",
    "        if rmse is not None and rmse > 0.27:  # NAO ESTA FUNCIONANDO IGNORAR RMSE=0\n",
    "            G.add_edge(i, j, weight=rmse)\n",
    "\n",
    "print(f\"Arestas adicionadas ao grafo: {G.number_of_edges()}\")\n",
    "\n",
    "# Mostra o custo (rmse) de cada aresta que sai da imagem \"002\"\n",
    "no_origem = \"004\"\n",
    "for vizinho in G.neighbors(no_origem):\n",
    "    custo = G[no_origem][vizinho]['weight']\n",
    "    print(f\"Aresta {no_origem} -> {vizinho}: custo (rmse) = {custo:.4f}\")\n",
    "\n",
    "# Exemplo: encontra o menor caminho (menor soma de rmse) entre duas imagens\n",
    "origem = \"000\"  # nó inicial (pode alterar)\n",
    "destino = \"060\" # nó final (pode alterar)\n",
    "\n",
    "try:\n",
    "    inicio = \"000\"\n",
    "    fim = \"060\"\n",
    "    caminho = caminho_guloso(G, inicio, fim)\n",
    "    print(\"Caminho guloso do\", inicio, \"até\", fim, \":\", caminho)\n",
    "    # ...existing code...\n",
    "except nx.NetworkXNoPath:\n",
    "    print(f\"Não existe caminho entre {origem} e {destino}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_MC949",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
