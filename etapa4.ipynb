{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c2d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219143e2",
   "metadata": {},
   "source": [
    "## Funções Auxiliares (Carregamento, Salvamento e Visualização)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19d37d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def desserializar_keypoints(arr: np.ndarray) -> List[cv2.KeyPoint]:\n",
    "    \"\"\"\n",
    "    Reconstrói lista de cv2.KeyPoint a partir do array (N,7).\n",
    "    \"\"\"\n",
    "    kps = []\n",
    "    for row in arr:\n",
    "        k = cv2.KeyPoint(\n",
    "            x=float(row[0]), y=float(row[1]), size=float(row[2]),\n",
    "            angle=float(row[3]), response=float(row[4]),\n",
    "            octave=int(row[5]), class_id=int(row[6])\n",
    "        )\n",
    "        kps.append(k)\n",
    "    return kps\n",
    "\n",
    "\n",
    "def carregar_features_npz(caminho_npz: str) -> Tuple[List[cv2.KeyPoint], np.ndarray, str]:\n",
    "    \"\"\"\n",
    "    Lê um .npz salvo pela Etapa 2 e retorna (keypoints, descriptors, imagem_absoluta).\n",
    "    \"\"\"\n",
    "    with np.load(caminho_npz, allow_pickle=True) as data:\n",
    "        kps = desserializar_keypoints(data[\"keypoints\"])\n",
    "        desc = data[\"descriptors\"]\n",
    "        img_path = str(data[\"imagem_absoluta\"])\n",
    "    return kps, desc, img_path\n",
    "\n",
    "\n",
    "def carregar_matches_npz(caminho_npz) -> List[cv2.DMatch]:\n",
    "    \"\"\"\n",
    "    Carrega os matches salvos em .npz e restaura cada linha como um objeto cv2.DMatch.\n",
    "    Retorna uma lista de cv2.DMatch.\n",
    "    \"\"\"\n",
    "\n",
    "    with np.load(caminho_npz, allow_pickle=True) as data:\n",
    "        arr = data[\"matches\"]  # array shape (N, 3)\n",
    "        matches = []\n",
    "        for row in arr:\n",
    "            # cv2.DMatch(queryIdx, trainIdx, distance)\n",
    "            m = cv2.DMatch(_queryIdx=int(row[0]), _trainIdx=int(row[1]), _distance=float(row[2]))\n",
    "            matches.append(m)\n",
    "    return matches\n",
    "\n",
    "\n",
    "def calcular_homogr(kps1, kps2, matches, params = None, direction = '2to1'):\n",
    "    \"\"\"\n",
    "    Calcula a homografia entre duas imagens usando os pontos correspondentes.\n",
    "    \"\"\"\n",
    "    if not kps1 or not kps2 or not matches or len(matches) < 4:\n",
    "        return None, None\n",
    "\n",
    "    # Extrai os pontos-chave e descritores\n",
    "    pts1 = [kps1[m.queryIdx].pt for m in matches]\n",
    "    pts2 = [kps2[m.trainIdx].pt for m in matches]\n",
    "\n",
    "    src, dst = (pts2, pts1) if direction == \"2to1\" else (pts1, pts2)\n",
    "\n",
    "    # Calcula a homografia usando RANSAC\n",
    "    H, mask = cv2.findHomography(np\n",
    "                                 .array(src, dtype=np.float32), np.array(dst, dtype=np.float32), cv2.RANSAC, **(params or {}))\n",
    "\n",
    "    return H, mask\n",
    "\n",
    "def alinhar_imgs(img1, img2, homografia):\n",
    "    if homografia is None:\n",
    "        return None\n",
    "    \n",
    "    h1, w1 = img1.shape[:2]\n",
    "    h2, w2 = img2.shape[:2]\n",
    "\n",
    "    # Cantos da imagem 2\n",
    "    cantos2 = np.array([[0,0],[w2,0],[w2,h2],[0,h2]], dtype=np.float32).reshape(-1,1,2)\n",
    "\n",
    "    # Aplica a homografia nos cantos da imagem 2\n",
    "    cantos2_trans = cv2.perspectiveTransform(cantos2, homografia)\n",
    "\n",
    "    # Combina com os cantos da imagem 1 para calcular o retangulo final\n",
    "    cantos_totais = np.vstack((cantos2_trans, np.array([[0,0],[w1,0],[w1,h1],[0,h1]], dtype=np.float32).reshape(-1,1,2)))\n",
    "    xmin, ymin = np.floor(cantos_totais.min(axis=0).ravel()).astype(np.int32)\n",
    "    xmax, ymax = np.ceil(cantos_totais.max(axis=0).ravel()).astype(np.int32)\n",
    "\n",
    "    # Translacao para coordenadas positivas\n",
    "    translacao = [-xmin, -ymin]\n",
    "    T = np.array([[1,0,translacao[0]], [0,1,translacao[1]], [0,0,1]], dtype=np.float64)\n",
    "\n",
    "    # Aplica warpPerspective com a homografia ajustada\n",
    "    res = cv2.warpPerspective(img2, T @ homografia, (xmax - xmin, ymax - ymin))\n",
    "\n",
    "    # Coloca img1 na posição correta\n",
    "    res[translacao[1]:translacao[1]+h1, translacao[0]:translacao[0]+w1] = img1\n",
    "\n",
    "    return res\n",
    "\n",
    "def salvar_homogr_npz(dir_saida, i, j, H, mask, path1, path2, metrics, params=None, direction=\"2to1\"):\n",
    "    os.makedirs(dir_saida, exist_ok=True)\n",
    "    mask_arr = np.asarray(mask, dtype=np.uint8).reshape(-1,1) if mask is not None else np.zeros((0,1), np.uint8)\n",
    "    np.savez_compressed(\n",
    "        os.path.join(dir_saida, f\"homogr_{i:03d}_{j:03d}.npz\"),\n",
    "        H=np.asarray(H, dtype=np.float32) if H is not None else np.zeros((3,3), np.float32),\n",
    "        mask=mask_arr,\n",
    "        inliers=np.int32(metrics.get(\"inliers\", 0)),\n",
    "        total=np.int32(metrics.get(\"total\", 0)),\n",
    "        rmse_px=np.float32(metrics.get(\"rmse_px\") if metrics.get(\"rmse_px\") is not None else np.nan),\n",
    "        direction=str(direction),                 # \"2to1\" => img2 -> img1\n",
    "        params_json=json.dumps(params or {}),     # p/ reprodutibilidade\n",
    "        idx_i=np.int32(i), idx_j=np.int32(j),\n",
    "        path_i=str(path1), path_j=str(path2)\n",
    "    )\n",
    "\n",
    "def carregar_homogr_npz(caminho_npz):\n",
    "    \"\"\"\n",
    "    Lê homogr_*.npz e retorna:\n",
    "      H (3x3 float32), mask (Nx1 uint8), meta (dict: inliers, total, rmse_px, direction, params_json, idx_i, idx_j, path_i, path_j)\n",
    "    \"\"\"\n",
    "    with np.load(caminho_npz, allow_pickle=True) as d:\n",
    "        H = d[\"H\"].astype(np.float32)\n",
    "        mask = d[\"mask\"].astype(np.uint8)\n",
    "        meta = {\n",
    "            \"inliers\": int(d[\"inliers\"]),\n",
    "            \"total\": int(d[\"total\"]),\n",
    "            \"rmse_px\": None if np.isnan(d[\"rmse_px\"]) else float(d[\"rmse_px\"]),\n",
    "            \"direction\": str(d[\"direction\"]),\n",
    "            \"params_json\": str(d[\"params_json\"]),\n",
    "            \"idx_i\": int(d[\"idx_i\"]), \"idx_j\": int(d[\"idx_j\"]),\n",
    "            \"path_i\": str(d[\"path_i\"]), \"path_j\": str(d[\"path_j\"]),\n",
    "        }\n",
    "    return H, mask, meta\n",
    "\n",
    "def carregar_homogr_dir(dir_homogr):\n",
    "    arquivos = sorted(glob.glob(os.path.join(dir_homogr, \"homogr_*.npz\")))\n",
    "    dados = []\n",
    "    for f in arquivos:\n",
    "        H, mask, meta = carregar_homogr_npz(f)\n",
    "        dados.append((H, mask, meta, f))\n",
    "    return dados  # lista de tuplas (H, mask, meta, caminho)\n",
    "\n",
    "def _rmse_reproj(H, pts_src, pts_dst, mask):\n",
    "    if H is None or mask is None or not mask.any():\n",
    "        return None\n",
    "    sel = mask.ravel().astype(bool)\n",
    "    if sel.sum() < 4:\n",
    "        return None\n",
    "    src = np.float32(pts_src)[sel]  # pts_src no sistema da imagem de origem em H\n",
    "    dst = np.float32(pts_dst)[sel]  # pts_dst no sistema de destino\n",
    "    src_h = cv2.convertPointsToHomogeneous(src).reshape(-1,3).T\n",
    "    proj = (H @ src_h); proj = (proj[:2] / proj[2]).T\n",
    "    dif = dst - proj\n",
    "    return float(np.sqrt((dif**2).sum(axis=1).mean()))\n",
    "\n",
    "# CHANGED\n",
    "def listar_pares_de_matches(caminho_matcher_dir, only_sequential: bool = True, n_imgs: int | None = None):\n",
    "    \"\"\"\n",
    "    Retorna lista de tuplas (i, j, caminho_npz_ou_None, reversed_bool).\n",
    "    - only_sequential=True: exatamente os pares (i, (i+1)%n), na ordem, incluindo wrap (n-1, 0).\n",
    "    - only_sequential=False: retorna todos os matches_*.npz encontrados como (i,j,path,False).\n",
    "    \"\"\"\n",
    "    arquivos = sorted(glob.glob(os.path.join(caminho_matcher_dir, \"matches_*.npz\")))\n",
    "    parsed = []\n",
    "    for arq in arquivos:\n",
    "        base = os.path.splitext(os.path.basename(arq))[0]  # matches_000_001\n",
    "        parts = base.split(\"_\")\n",
    "        if len(parts) < 3:\n",
    "            continue\n",
    "        _, si, sj = parts[:3]\n",
    "        parsed.append((int(si), int(sj), arq))\n",
    "\n",
    "    if not only_sequential:\n",
    "        # todos os arquivos existentes, sem reversed (pois já estão no sentido do nome do arquivo)\n",
    "        return [(i, j, path, False) for (i, j, path) in parsed]\n",
    "\n",
    "    # --- sequenciais com wrap ---\n",
    "    if n_imgs is None:\n",
    "        idxs = set()\n",
    "        for i, j, _ in parsed:\n",
    "            idxs.update([i, j])\n",
    "        n = max(idxs) + 1 if idxs else 0\n",
    "    else:\n",
    "        n = int(n_imgs)\n",
    "\n",
    "    out = []\n",
    "    for i in range(n):\n",
    "        j = (i + 1) % n\n",
    "        path, reversed_flag = _resolve_caminho_matches(caminho_matcher_dir, i, j)\n",
    "        out.append((i, j, path, bool(reversed_flag)))\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RANSAC em cascata (do mais rígido ao menos rígido)  # NEW\n",
    "RANSAC_CANDIDATOS_RIGOROSOS = [\n",
    "    {\"ransacReprojThreshold\": 1.0, \"maxIters\": 22000, \"confidence\": 0.9997},\n",
    "    {\"ransacReprojThreshold\": 1.4, \"maxIters\": 20000, \"confidence\": 0.9995},\n",
    "    {\"ransacReprojThreshold\": 1.8, \"maxIters\": 18000, \"confidence\": 0.9990},\n",
    "]\n",
    "\n",
    "def _rmse_simetrico(H, pts2, pts1, mask):  # NEW\n",
    "    if H is None or mask is None or not np.any(mask):\n",
    "        return None\n",
    "    sel = mask.ravel().astype(bool)\n",
    "    if sel.sum() < 4:\n",
    "        return None\n",
    "    p1 = np.float32(pts1)[sel]\n",
    "    p2 = np.float32(pts2)[sel]\n",
    "    try:\n",
    "        Hinv = np.linalg.inv(H)\n",
    "    except np.linalg.LinAlgError:\n",
    "        return None\n",
    "    def _proj(P, M):\n",
    "        Ph = cv2.convertPointsToHomogeneous(P).reshape(-1,3).T\n",
    "        Q  = (M @ Ph); Q = (Q[:2] / Q[2]).T\n",
    "        return Q\n",
    "    e_fwd = np.linalg.norm(p1 - _proj(p2, H),   axis=1)  # 2->1\n",
    "    e_bwd = np.linalg.norm(p2 - _proj(p1, Hinv), axis=1) # 1->2\n",
    "    e = 0.5*(e_fwd + e_bwd)\n",
    "    return float(np.sqrt((e**2).mean()))\n",
    "\n",
    "def _homografia_saudavel_bbox(H, shape_src, shape_dst, fator_max_bbox=6.0):  # NEW\n",
    "    if H is None or not np.isfinite(H).all(): return False\n",
    "    h2, w2 = shape_src[:2]\n",
    "    if h2 <= 0 or w2 <= 0: return False\n",
    "    cantos2 = np.float32([[0,0],[w2,0],[w2,h2],[0,h2]]).reshape(-1,1,2)\n",
    "    try:\n",
    "        proj = cv2.perspectiveTransform(cantos2, H)\n",
    "    except cv2.error:\n",
    "        return False\n",
    "    if not np.isfinite(proj).all(): return False\n",
    "    xs = proj[:,0,0]; ys = proj[:,0,1]\n",
    "    bw = float(xs.max() - xs.min()); bh = float(ys.max() - ys.min())\n",
    "    if bw <= 0 or bh <= 0: return False\n",
    "    h1, w1 = shape_dst[:2]\n",
    "    diag_ref  = max((h1*h1 + w1*w1) ** 0.5, (h2*h2 + w2*w2) ** 0.5)\n",
    "    diag_proj = (bw*bw + bh*bh) ** 0.5\n",
    "    return (diag_proj <= fator_max_bbox * float(diag_ref))\n",
    "\n",
    "def _condicionamento_ok(H, max_kappa=1e6):  # NEW\n",
    "    if H is None or not np.isfinite(H).all(): return False\n",
    "    try:\n",
    "        s = np.linalg.svd(H, compute_uv=False)\n",
    "    except np.linalg.LinAlgError:\n",
    "        return False\n",
    "    if s[-1] == 0: return False\n",
    "    kappa = float(s[0] / s[-1])\n",
    "    return (kappa <= max_kappa)\n",
    "\n",
    "def checar_integridade_H(H, mask, pts2, pts1, img1, img2,\n",
    "                         min_inliers=12, max_rmse=3.0, max_kappa=1e6, fator_max_bbox=6.0):\n",
    "    \"\"\"\n",
    "    Retorna (ok: bool, metrics: dict, reason: str|None)\n",
    "      metrics: 'inliers', 'total', 'rmse_px', 'rmse_sym', 'kappa'\n",
    "      reason: motivo textual da reprova (para visualização/debug; NÃO é salvo)\n",
    "    \"\"\"\n",
    "    metrics = {\"inliers\": 0, \"total\": len(pts1), \"rmse_px\": None, \"rmse_sym\": None, \"kappa\": None}\n",
    "\n",
    "    # 1) Existência\n",
    "    if H is None or mask is None:\n",
    "        return False, metrics, \"sem H ou mask\"\n",
    "\n",
    "    inl = int(mask.sum())\n",
    "    metrics[\"inliers\"] = inl\n",
    "\n",
    "    # 2) Inliers mínimos\n",
    "    if inl < min_inliers:\n",
    "        return False, metrics, f\"poucos inliers ({inl} < {min_inliers})\"\n",
    "\n",
    "    # 3) RMSE direcional (2->1) e simétrico\n",
    "    try:\n",
    "        rmse_dir = _rmse_reproj(H, pts2, pts1, mask)  # se já existir no arquivo\n",
    "    except NameError:\n",
    "        sel = mask.ravel().astype(bool)\n",
    "        if sel.sum() >= 4:\n",
    "            src = np.float32(pts2)[sel]; dst = np.float32(pts1)[sel]\n",
    "            src_h = cv2.convertPointsToHomogeneous(src).reshape(-1,3).T\n",
    "            proj = (H @ src_h); proj = (proj[:2] / proj[2]).T\n",
    "            dif = dst - proj\n",
    "            rmse_dir = float(np.sqrt((dif**2).sum(axis=1).mean()))\n",
    "        else:\n",
    "            rmse_dir = None\n",
    "    metrics[\"rmse_px\"] = rmse_dir\n",
    "\n",
    "    rmse_sym = _rmse_simetrico(H, pts2, pts1, mask)\n",
    "    metrics[\"rmse_sym\"] = rmse_sym\n",
    "\n",
    "    if (rmse_dir is None or rmse_dir > max_rmse) and (rmse_sym is None or rmse_sym > max_rmse):\n",
    "        rd = f\"{rmse_dir:.2f}\" if rmse_dir is not None else \"None\"\n",
    "        rs = f\"{rmse_sym:.2f}\" if rmse_sym is not None else \"None\"\n",
    "        return False, metrics, f\"RMSE alto (dir={rd}, sym={rs} > {max_rmse})\"\n",
    "\n",
    "    # 4) Condicionamento\n",
    "    try:\n",
    "        s = np.linalg.svd(H, compute_uv=False)\n",
    "        kappa = float(s[0] / s[-1]) if s[-1] != 0 else np.inf\n",
    "    except np.linalg.LinAlgError:\n",
    "        kappa = np.inf\n",
    "    metrics[\"kappa\"] = kappa\n",
    "    if not _condicionamento_ok(H, max_kappa=max_kappa):\n",
    "        return False, metrics, f\"condicionamento ruim (kappa={kappa:.2e} > {max_kappa:.1e})\"\n",
    "\n",
    "    # 5) Sanidade geométrica (bbox)\n",
    "    if not _homografia_saudavel_bbox(H, img2.shape, img1.shape, fator_max_bbox=fator_max_bbox):\n",
    "        return False, metrics, \"bbox projetada exagerada\"\n",
    "\n",
    "    # OK\n",
    "    return True, metrics, None\n",
    "\n",
    "\n",
    "# CHANGED: agora aceita fator_max_bbox e usa título compactado\n",
    "def visualizar_par(img1, img2, H, titulo=\"Pré-visualização do par\", metrics=None, bbox_factor=None):\n",
    "    if img1 is None or img2 is None or H is None:\n",
    "        return\n",
    "    h1, w1 = img1.shape[:2]\n",
    "    warped = cv2.warpPerspective(img2, H, (w1, h1))\n",
    "    blend  = cv2.addWeighted(img1, 0.6, warped, 0.4, 0)\n",
    "\n",
    "    # cantos projetados de img2 no frame de img1\n",
    "    h2, w2 = img2.shape[:2]\n",
    "    cant2  = np.float32([[0,0],[w2,0],[w2,h2],[0,h2]]).reshape(-1,1,2)\n",
    "    poly   = cv2.perspectiveTransform(cant2, H).reshape(-1,2)\n",
    "\n",
    "    # calcula bbox_factor se não vier de fora\n",
    "    if bbox_factor is None:\n",
    "        bbox_factor = _bbox_factor(H, img2.shape, img1.shape)\n",
    "\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.imshow(cv2.cvtColor(blend, cv2.COLOR_BGR2RGB))\n",
    "    xs = np.r_[poly[:,0], poly[0,0]]; ys = np.r_[poly[:,1], poly[0,1]]\n",
    "    plt.plot(xs, ys, 'r-', lw=2)\n",
    "    if metrics:\n",
    "        txt = _format_preview_metrics(metrics, bbox_factor=bbox_factor)\n",
    "        plt.title(f\"{titulo}\\n{txt}\")\n",
    "    else:\n",
    "        plt.title(titulo)\n",
    "    plt.axis('off'); plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# NEW helper: formatação compacta para o título do preview\n",
    "def _format_preview_metrics(metrics, bbox_factor=None):\n",
    "    import math\n",
    "    def f2(x):\n",
    "        if x is None or (isinstance(x, float) and (math.isnan(x) or math.isinf(x))):\n",
    "            return \"—\"\n",
    "        return f\"{x:.2f}\"\n",
    "    def fexp(x):\n",
    "        if x is None or (isinstance(x, float) and (math.isnan(x) or math.isinf(x))):\n",
    "            return \"—\"\n",
    "        return f\"{x:.2e}\"\n",
    "    inl   = metrics.get(\"inliers\", \"—\")\n",
    "    rmse  = f2(metrics.get(\"rmse_px\"))\n",
    "    rsym  = f2(metrics.get(\"rmse_sym\"))\n",
    "    kappa = fexp(metrics.get(\"kappa\"))\n",
    "    extra = f\", bbox={bbox_factor:.2f}×diag\" if (bbox_factor is not None) else \"\"\n",
    "    return f\"inliers={inl}, rmse={rmse}, rmse_sym={rsym}, kappa={kappa}{extra}\"\n",
    "\n",
    "\n",
    "def _bbox_factor(H, shape_src, shape_dst):\n",
    "    \"\"\"\n",
    "    Retorna o fator (diag_bbox_proj / diag_ref), onde:\n",
    "      - diag_bbox_proj = diagonal do retângulo mínimo que contém os 4 cantos da src projetados por H no frame dst\n",
    "      - diag_ref = max(diagonal da src, diagonal da dst)\n",
    "    Se não for possível calcular, retorna None.\n",
    "    \"\"\"\n",
    "    if H is None or not np.isfinite(H).all():\n",
    "        return None\n",
    "    h2, w2 = shape_src[:2]\n",
    "    h1, w1 = shape_dst[:2]\n",
    "    if h2 <= 0 or w2 <= 0 or h1 <= 0 or w1 <= 0:\n",
    "        return None\n",
    "\n",
    "    cantos2 = np.float32([[0,0],[w2,0],[w2,h2],[0,h2]]).reshape(-1,1,2)\n",
    "    try:\n",
    "        proj = cv2.perspectiveTransform(cantos2, H)\n",
    "    except cv2.error:\n",
    "        return None\n",
    "    if not np.isfinite(proj).all():\n",
    "        return None\n",
    "\n",
    "    xs = proj[:,0,0]; ys = proj[:,0,1]\n",
    "    bw = float(xs.max() - xs.min()); bh = float(ys.max() - ys.min())\n",
    "    if bw <= 0 or bh <= 0:\n",
    "        return None\n",
    "\n",
    "    diag_proj = (bw*bw + bh*bh) ** 0.5\n",
    "    diag_src  = (h2*h2 + w2*w2) ** 0.5\n",
    "    diag_dst  = (h1*h1 + w1*w1) ** 0.5\n",
    "    diag_ref  = max(diag_src, diag_dst)\n",
    "    if diag_ref <= 0:\n",
    "        return None\n",
    "\n",
    "    return float(diag_proj / diag_ref)\n",
    "\n",
    "# NEW: encontra o arquivo de matches do par (i,j); se só existir (j,i), marca como reversed=True\n",
    "def _resolve_caminho_matches(caminho_matcher_dir: str, i: int, j: int):\n",
    "    p_ij = os.path.join(caminho_matcher_dir, f\"matches_{i:03d}_{j:03d}.npz\")\n",
    "    if os.path.exists(p_ij):\n",
    "        return p_ij, False\n",
    "    p_ji = os.path.join(caminho_matcher_dir, f\"matches_{j:03d}_{i:03d}.npz\")\n",
    "    if os.path.exists(p_ji):\n",
    "        return p_ji, True\n",
    "    return None, None\n",
    "\n",
    "# NEW: inverte query/train dos DMatch quando o arquivo é (j,i) mas queremos (i,j)\n",
    "def _inverter_matches(matches: List[cv2.DMatch]) -> List[cv2.DMatch]:\n",
    "    inv = []\n",
    "    for m in matches:\n",
    "        inv.append(cv2.DMatch(_queryIdx=m.trainIdx, _trainIdx=m.queryIdx, _distance=float(m.distance)))\n",
    "    return inv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1b6a00",
   "metadata": {},
   "source": [
    "## Pipeline Principal da Etapa 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff561d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGED: função principal com preview exibindo fator_max_bbox e métricas formatadas\n",
    "def analisar_homogr_alinhamento(caminho_base_etapa2: str, caminho_base_etapa3: str, detectores: List[str], matchers: List[str],\n",
    "                                ransac_cfg=None, gerar_preview: bool = True, only_sequential: bool = True,\n",
    "                                validate_H: bool = True, validation_cfg: dict | None = None):\n",
    "    \"\"\"\n",
    "    Etapa 4: (re)calcula homografias e salva homogr_*.npz.\n",
    "\n",
    "    Parâmetros:\n",
    "      - only_sequential: True => processa apenas pares sequenciais com wrap (i, (i+1)%n);\n",
    "                          False => processa todos os pares encontrados em matches_*.npz.\n",
    "      - validate_H: ativa validação avançada (inliers / RMSE / condicionamento / bbox).\n",
    "      - validation_cfg: dict opcional para thresholds e/ou lista 'candidatos' de RANSAC.\n",
    "          chaves aceitas:\n",
    "            min_inliers (int), max_rmse (float), max_kappa (float),\n",
    "            fator_max_bbox (float), candidatos (list[dict])\n",
    "      - ransac_cfg: utilizado SOMENTE quando validate_H=False (uma única rodada de RANSAC).\n",
    "      - gerar_preview: exibe visualização por par (não salva imagens).\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*65}\\nHomografia e alinhamento para o conjunto: '{os.path.basename(caminho_base_etapa3)}'\\n{'='*65}\")\n",
    "\n",
    "    # Carrega ordem (apenas para logs/consistência)\n",
    "    caminho_json = os.path.join(caminho_base_etapa2, \"ordem_imagens.json\")\n",
    "    try:\n",
    "        with open(caminho_json, \"r\") as f:\n",
    "            arquivos_de_imagem_abs = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[Erro] 'ordem_imagens.json' não encontrado em '{caminho_base_etapa2}'. Abortando.\")\n",
    "        return\n",
    "\n",
    "    # Config de validação\n",
    "    vcfg = validation_cfg or {}\n",
    "    min_inl    = int(vcfg.get(\"min_inliers\", 12))\n",
    "    max_rmse   = float(vcfg.get(\"max_rmse\", 3.0))\n",
    "    max_kappa  = float(vcfg.get(\"max_kappa\", 1e6))\n",
    "    fator_bbox = float(vcfg.get(\"fator_max_bbox\", 6.0))\n",
    "    candidatos = vcfg.get(\"candidatos\", RANSAC_CANDIDATOS_RIGOROSOS)\n",
    "\n",
    "    # Itera detectores\n",
    "    for nome_detector in detectores:\n",
    "        print(f\"\\n--- Detector: {nome_detector.upper()} ---\")\n",
    "        caminho_detector = os.path.join(caminho_base_etapa2, nome_detector)\n",
    "        arquivos_feature_npz = sorted(glob.glob(os.path.join(caminho_detector, \"*_features.npz\")))\n",
    "        n_imgs = len(arquivos_feature_npz)\n",
    "        if n_imgs < 2:\n",
    "            print(\"  [Aviso] Menos de 2 imagens com features; pulando.\")\n",
    "            continue\n",
    "\n",
    "        # Itera matchers\n",
    "        for nome_matcher in matchers:\n",
    "            print(f\"  - {nome_detector.upper()} / {nome_matcher.upper()}\")\n",
    "            caminho_matcher = os.path.join(caminho_base_etapa3, nome_detector, nome_matcher)\n",
    "            dir_saida = os.path.join(\"resultados_etapa4\", os.path.basename(caminho_base_etapa3), nome_detector, nome_matcher)\n",
    "            os.makedirs(dir_saida, exist_ok=True)\n",
    "\n",
    "            # CHANGED: montar pares sequenciais com wrap usando os arquivos já existentes\n",
    "            pares = listar_pares_de_matches(\n",
    "                caminho_matcher,\n",
    "                only_sequential=True if only_sequential else False,\n",
    "                n_imgs=n_imgs\n",
    "            )\n",
    "            if not pares:\n",
    "                print(\"    [Aviso] Nenhum matches_*.npz encontrado.\")\n",
    "                continue\n",
    "\n",
    "\n",
    "            # CHANGED: logo no começo do loop de pares, antes de carregar matches\n",
    "            # CHANGED: agora recebe também reversed_flag\n",
    "            for (i, j, caminho_npz_matches, reversed_flag) in pares:\n",
    "                # Garantia de processar o wrap: se faltar arquivo, loga e segue\n",
    "                if caminho_npz_matches is None:\n",
    "                    print(f\"    [Aviso] Arquivo de matches ausente para par {i:03d}-{j:03d} (wrap incluído).\")\n",
    "                    continue\n",
    "                \n",
    "                # Carrega features / imagens\n",
    "                kps1, desc1, path1 = carregar_features_npz(arquivos_feature_npz[i])\n",
    "                kps2, desc2, path2 = carregar_features_npz(arquivos_feature_npz[j])\n",
    "                img1 = cv2.imread(path1); img2 = cv2.imread(path2)\n",
    "            \n",
    "                # Carrega matches do arquivo\n",
    "                match_data = carregar_matches_npz(caminho_npz_matches)\n",
    "            \n",
    "                # Se o arquivo estava no sentido (j,i), invertimos os índices para alinhar com (i,j)\n",
    "                if reversed_flag:\n",
    "                    match_data = _inverter_matches(match_data)\n",
    "            \n",
    "                if not kps1 or not kps2 or not match_data:\n",
    "                    salvar_homogr_npz(dir_saida, i, j, None, None, path1, path2,\n",
    "                                      metrics={\"inliers\":0,\"total\":0,\"rmse_px\":None},\n",
    "                                      params={}, direction=\"2to1\")\n",
    "                    if gerar_preview:\n",
    "                        visualizar_par(img1, img2, None, titulo=f\"Par {i}-{j} • sem H (sem matches suficientes)\")\n",
    "                    continue\n",
    "\n",
    "                # ... (resto da função permanece igual)\n",
    "\n",
    "\n",
    "                # Pontos 2->1\n",
    "                pts1 = [kps1[m.queryIdx].pt for m in match_data]  # destino (img1)\n",
    "                pts2 = [kps2[m.trainIdx].pt for m in match_data]  # origem  (img2)\n",
    "\n",
    "                if validate_H:\n",
    "                    H_ok = None; M_ok = None; metrics_ok = None; cfg_ok = None\n",
    "                    reason_last = None; metrics_last = None\n",
    "                    for cfg in candidatos:\n",
    "                        H_try, M_try = calcular_homogr(kps1, kps2, match_data, cfg, '2to1')\n",
    "                        ok, metrics, reason = checar_integridade_H(\n",
    "                            H_try, M_try, pts2, pts1, img1, img2,\n",
    "                            min_inliers=min_inl, max_rmse=max_rmse,\n",
    "                            max_kappa=max_kappa, fator_max_bbox=fator_bbox\n",
    "                        )\n",
    "                        if ok:\n",
    "                            H_ok, M_ok, metrics_ok, cfg_ok = H_try, M_try, metrics, cfg\n",
    "                            break\n",
    "                        reason_last = reason\n",
    "                        metrics_last = metrics\n",
    "\n",
    "                    if H_ok is not None:\n",
    "                        if gerar_preview:\n",
    "                            bf = _bbox_factor(H_ok, img2.shape, img1.shape)  # NEW\n",
    "                            visualizar_par(\n",
    "                                img1, img2, H_ok,\n",
    "                                titulo=f\"Par {i}-{j} • Homografia VÁLIDA\",\n",
    "                                metrics=metrics_ok,\n",
    "                                bbox_factor=bf  # CHANGED\n",
    "                            )\n",
    "\n",
    "                        salvar_homogr_npz(dir_saida, i, j, H_ok, M_ok, path1, path2,\n",
    "                                          metrics={\"inliers\":metrics_ok[\"inliers\"],\n",
    "                                                   \"total\":metrics_ok[\"total\"],\n",
    "                                                   \"rmse_px\":metrics_ok[\"rmse_px\"]},\n",
    "                                          params=cfg_ok, direction=\"2to1\")\n",
    "                    else:\n",
    "                        if gerar_preview and 'H_try' in locals() and H_try is not None:\n",
    "                            tit = f\"Par {i}-{j} • Homografia REPROVADA — {reason_last}\"\n",
    "                            bf  = _bbox_factor(H_try, img2.shape, img1.shape)  # NEW\n",
    "                            visualizar_par(\n",
    "                                img1, img2, H_try,\n",
    "                                titulo=tit,\n",
    "                                metrics=metrics_last if metrics_last is not None else {},\n",
    "                                bbox_factor=bf  # CHANGED\n",
    "                            )\n",
    "\n",
    "                        salvar_homogr_npz(dir_saida, i, j, None, None, path1, path2,\n",
    "                                          metrics={\"inliers\":0,\"total\":len(match_data),\"rmse_px\":None},\n",
    "                                          params=candidatos[-1] if candidatos else {}, direction=\"2to1\")\n",
    "\n",
    "                else:\n",
    "                    # Caminho simples: uma rodada de RANSAC\n",
    "                    H, M = calcular_homogr(kps1, kps2, match_data, ransac_cfg or {}, '2to1')\n",
    "                    inliers = int(M.sum()) if M is not None else 0\n",
    "                    rmse    = _rmse_reproj(H, pts2, pts1, M) if (H is not None and M is not None) else None\n",
    "                    if gerar_preview and H is not None:\n",
    "                        bf = _bbox_factor(H, img2.shape, img1.shape)  # NEW\n",
    "                        visualizar_par(\n",
    "                            img1, img2, H,\n",
    "                            titulo=f\"Par {i}-{j} • H sem validação\",\n",
    "                            metrics={\"inliers\":inliers,\"total\":len(match_data),\"rmse_px\":rmse},\n",
    "                            bbox_factor=bf  # CHANGED\n",
    "                        )\n",
    "\n",
    "                    salvar_homogr_npz(dir_saida, i, j, H, M, path1, path2,\n",
    "                                      metrics={\"inliers\":inliers,\"total\":len(match_data),\"rmse_px\":rmse},\n",
    "                                      params=ransac_cfg or {}, direction=\"2to1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9415e9",
   "metadata": {},
   "source": [
    "## Execução do Pipeline para os Conjuntos de Imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8704cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAIZ_ETAPA2 = \"resultados_etapa2\"\n",
    "RAIZ_ETAPA3 = \"resultados_etapa3\"\n",
    "DETECTORS = ['sift', 'orb', 'akaze']\n",
    "MATCHERS = ['bf', 'flann']\n",
    "ONLY_SEQUENTIAL = True\n",
    "GERAR_PREVIEW = True\n",
    "VALIDATE_H = True\n",
    "\n",
    "conjuntos = [d for d in os.listdir(RAIZ_ETAPA2) if os.path.isdir(os.path.join(RAIZ_ETAPA2, d))]\n",
    "#conjuntos = [\"images-developed-tiff-16bit\",\"images-developed-tiff-8bit\"]\n",
    "\n",
    "validation_cfg = {\n",
    "    \"min_inliers\": 8,\n",
    "    \"max_rmse\": 1,\n",
    "    \"max_kappa\": 3e6,\n",
    "    \"fator_max_bbox\": 1.6,\n",
    "    \"candidatos\": [  # opcional: substitui RANSAC_CANDIDATOS_RIGOROSOS\n",
    "         {\"ransacReprojThreshold\": 0.75, \"maxIters\":30000, \"confidence\": 0.9999},\n",
    "         {\"ransacReprojThreshold\": 0.9, \"maxIters\": 24000, \"confidence\": 0.9997},\n",
    "         {\"ransacReprojThreshold\": 1.3, \"maxIters\": 20000, \"confidence\": 0.9995},\n",
    "         {\"ransacReprojThreshold\": 1.8, \"maxIters\": 18000, \"confidence\": 0.9990},\n",
    "    ]\n",
    "}\n",
    "\n",
    "ransac_cfg = validation_cfg[\"candidatos\"][0] if \"candidatos\" in validation_cfg else None\n",
    "\n",
    "for nome_conjunto in sorted(conjuntos):\n",
    "    caminho_detector = os.path.join(RAIZ_ETAPA2, nome_conjunto)\n",
    "    caminho_matcher = os.path.join(RAIZ_ETAPA3, nome_conjunto)\n",
    "    analisar_homogr_alinhamento(caminho_detector, caminho_matcher, DETECTORS, MATCHERS, ransac_cfg, GERAR_PREVIEW,ONLY_SEQUENTIAL, VALIDATE_H, validation_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286bb65c",
   "metadata": {},
   "source": [
    "## Seleção de melhores homografias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863ca8d7",
   "metadata": {},
   "source": [
    "### Definição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e1510e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, json, math\n",
    "import numpy as np\n",
    "\n",
    "def compilar_melhores_homografias(\n",
    "    raiz_etapa4: str = \"resultados_etapa4\",\n",
    "    raiz_etapa2: str = \"resultados_etapa2\",\n",
    "    formatos: list[str] | None = None,\n",
    "    detectores: list[str] | None = None,\n",
    "    matchers: list[str] | None = None,\n",
    "    nome_detector_out: str = \"best\",\n",
    "    nome_matcher_out: str = \"best\",\n",
    "    usar_pares_sequenciais: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Para cada <formato> em resultados_etapa4, cria um diretório <formato>/best/best/\n",
    "    com a melhor homografia por par (escolhida entre todos os (detector,matcher)),\n",
    "    de forma compatível com a Etapa 5.\n",
    "\n",
    "    Critério:\n",
    "      1) Maior número de inliers (meta['inliers'])\n",
    "      2) Desempate por menor rmse_px (meta['rmse_px']) — NaN perde no desempate.\n",
    "\n",
    "    Se um par não tiver nenhuma H válida, salva sentinela inválida (H/mask None)\n",
    "    e agora **emite um warning**.\n",
    "    \"\"\"\n",
    "    if formatos is None:\n",
    "        formatos = [d for d in sorted(os.listdir(raiz_etapa4))\n",
    "                    if os.path.isdir(os.path.join(raiz_etapa4, d))]\n",
    "\n",
    "    for formato in formatos:\n",
    "        dir_formato_et4 = os.path.join(raiz_etapa4, formato)\n",
    "        if not os.path.isdir(dir_formato_et4):\n",
    "            continue\n",
    "\n",
    "        caminho_ordem = os.path.join(raiz_etapa2, formato, \"ordem_imagens.json\")\n",
    "        try:\n",
    "            with open(caminho_ordem, \"r\") as f:\n",
    "                caminhos_imgs = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"[Aviso] '{caminho_ordem}' não encontrado — pulando formato '{formato}'.\")\n",
    "            continue\n",
    "\n",
    "        n = len(caminhos_imgs)\n",
    "        if n < 2:\n",
    "            print(f\"[Aviso] Formato '{formato}' com menos de 2 imagens — pulando.\")\n",
    "            continue\n",
    "\n",
    "        dets = detectores or [d for d in sorted(os.listdir(dir_formato_et4))\n",
    "                              if os.path.isdir(os.path.join(dir_formato_et4, d))]\n",
    "        dir_out = os.path.join(raiz_etapa4, formato, nome_detector_out, nome_matcher_out)\n",
    "        os.makedirs(dir_out, exist_ok=True)\n",
    "\n",
    "        candidatos_por_par: dict[tuple[int,int], list[str]] = {}\n",
    "\n",
    "        if usar_pares_sequenciais:\n",
    "            pares = [(i, (i+1) % n) for i in range(n)]\n",
    "            for det in dets:\n",
    "                dir_det = os.path.join(dir_formato_et4, det)\n",
    "                if not os.path.isdir(dir_det): continue\n",
    "                mats = matchers or [m for m in sorted(os.listdir(dir_det))\n",
    "                                    if os.path.isdir(os.path.join(dir_det, m))]\n",
    "                for mat in mats:\n",
    "                    dir_mat = os.path.join(dir_det, mat)\n",
    "                    for (i, j) in pares:\n",
    "                        p = os.path.join(dir_mat, f\"homogr_{i:03d}_{j:03d}.npz\")\n",
    "                        if os.path.exists(p):\n",
    "                            candidatos_por_par.setdefault((i,j), []).append(p)\n",
    "            # NEW: garante chave para todos os pares sequenciais (mesmo sem arquivos)\n",
    "            for (i, j) in pares:  # NEW\n",
    "                candidatos_por_par.setdefault((i, j), [])  # NEW\n",
    "        else:\n",
    "            for det in dets:\n",
    "                dir_det = os.path.join(dir_formato_et4, det)\n",
    "                if not os.path.isdir(dir_det): continue\n",
    "                mats = matchers or [m for m in sorted(os.listdir(dir_det))\n",
    "                                    if os.path.isdir(os.path.join(dir_det, m))]\n",
    "                for mat in mats:\n",
    "                    dir_mat = os.path.join(dir_det, mat)\n",
    "                    for p in glob.glob(os.path.join(dir_mat, \"homogr_*.npz\")):\n",
    "                        base = os.path.splitext(os.path.basename(p))[0]  # homogr_000_001\n",
    "                        _, si, sj = base.split(\"_\")\n",
    "                        i, j = int(si), int(sj)\n",
    "                        candidatos_por_par.setdefault((i,j), []).append(p)\n",
    "\n",
    "        def _score(meta):\n",
    "            inl = meta.get(\"inliers\", 0) or 0\n",
    "            rmse = meta.get(\"rmse_px\", np.nan)\n",
    "            if rmse is None or (isinstance(rmse, float) and (math.isnan(rmse) or math.isinf(rmse))):\n",
    "                rmse = float(\"inf\")\n",
    "            return (-int(inl), float(rmse))\n",
    "\n",
    "        total_pares = len(candidatos_por_par)\n",
    "        if total_pares == 0:\n",
    "            print(f\"[Aviso] Nenhuma homografia encontrada em '{dir_formato_et4}'.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"[Info] Compilando '{formato}': {total_pares} pares...\")\n",
    "\n",
    "        for (i, j), caminhos_npz in sorted(candidatos_por_par.items()):\n",
    "            # NEW: warning se não há candidatos para o par (p.ex., arquivo inexistente)\n",
    "            if not caminhos_npz:  # NEW\n",
    "                print(f\"[Aviso] {formato}: par {i:03d}-{j:03d} sem arquivos de homografia em nenhum método.\")  # NEW\n",
    "                path_i = caminhos_imgs[i]; path_j = caminhos_imgs[j]\n",
    "                # salva sentinela inválida para manter compatibilidade com Etapa 5\n",
    "                salvar_homogr_npz(  # NEW\n",
    "                    dir_out, i, j,\n",
    "                    None, None,\n",
    "                    path_i, path_j,\n",
    "                    metrics={\"inliers\":0, \"total\":0, \"rmse_px\": None},\n",
    "                    params={}, direction=\"2to1\",\n",
    "                )\n",
    "                continue  # NEW\n",
    "\n",
    "            melhor = None\n",
    "            melhor_meta = None\n",
    "            melhor_mask = None\n",
    "            melhor_params = {}\n",
    "            melhor_src = None\n",
    "\n",
    "            for caminho in caminhos_npz:\n",
    "                H, mask, meta = carregar_homogr_npz(caminho)\n",
    "\n",
    "                try:\n",
    "                    parts = caminho.replace(\"\\\\\",\"/\").split(\"/\")\n",
    "                    idx_formato = parts.index(raiz_etapa4) + 1 if raiz_etapa4 in parts else None\n",
    "                    if idx_formato is None:\n",
    "                        idx_formato = parts.index(formato)\n",
    "                    det_src = parts[idx_formato+1]\n",
    "                    mat_src = parts[idx_formato+2]\n",
    "                except Exception:\n",
    "                    det_src, mat_src = \"?\", \"?\"\n",
    "\n",
    "                meta = dict(meta) if meta is not None else {}\n",
    "                sc = _score(meta)\n",
    "\n",
    "                if melhor is None or sc < _score(melhor_meta or {}):\n",
    "                    melhor = H\n",
    "                    melhor_mask = mask\n",
    "                    melhor_meta = meta\n",
    "                    melhor_params = meta.get(\"params_json\", {})\n",
    "                    melhor_src = (det_src, mat_src)\n",
    "\n",
    "            path_i = caminhos_imgs[i]\n",
    "            path_j = caminhos_imgs[j]\n",
    "\n",
    "            # CHANGED: warning explícito quando não há homografia válida (inliers<=0 ou H/mask ausentes)\n",
    "            if melhor is None or melhor_mask is None or (melhor_meta or {}).get(\"inliers\", 0) <= 0:\n",
    "                print(f\"[Aviso] {formato}: par {i:03d}-{j:03d} sem homografia VÁLIDA entre os métodos — salvando sentinela.\")  # NEW\n",
    "                salvar_homogr_npz(\n",
    "                    dir_out, i, j,\n",
    "                    None, None,\n",
    "                    path_i, path_j,\n",
    "                    metrics={\"inliers\":0, \"total\": int(melhor_meta.get(\"total\", 0)) if melhor_meta else 0, \"rmse_px\": None},\n",
    "                    params={},  # sem params\n",
    "                    direction=\"2to1\",\n",
    "                )\n",
    "            else:\n",
    "                params_out = melhor_params\n",
    "                if isinstance(params_out, dict):\n",
    "                    params_out = dict(params_out)\n",
    "                    params_out[\"_src_detector\"] = melhor_src[0]\n",
    "                    params_out[\"_src_matcher\"]  = melhor_src[1]\n",
    "                salvar_homogr_npz(\n",
    "                    dir_out, i, j,\n",
    "                    melhor, melhor_mask,\n",
    "                    path_i, path_j,\n",
    "                    metrics={\n",
    "                        \"inliers\": int(melhor_meta.get(\"inliers\", 0) or 0),\n",
    "                        \"total\":   int(melhor_meta.get(\"total\", 0)   or 0),\n",
    "                        \"rmse_px\": (None if (\"rmse_px\" not in melhor_meta) else melhor_meta.get(\"rmse_px\")),\n",
    "                    },\n",
    "                    params=params_out,\n",
    "                    direction=\"2to1\",\n",
    "                )\n",
    "\n",
    "        print(f\"[OK] Compilado criado em: {dir_out}\\n\"\n",
    "              f\"     Use na Etapa 5 com detector='{nome_detector_out}', matcher='{nome_matcher_out}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eb310f",
   "metadata": {},
   "source": [
    "### Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3922f2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Compilando 'images-developed-png-16bit': 30 pares...\n",
      "[OK] Compilado criado em: resultados_etapa4/images-developed-png-16bit/best/best\n",
      "     Use na Etapa 5 com detector='best', matcher='best'.\n",
      "[Info] Compilando 'images-developed-tiff-16bit': 30 pares...\n",
      "[OK] Compilado criado em: resultados_etapa4/images-developed-tiff-16bit/best/best\n",
      "     Use na Etapa 5 com detector='best', matcher='best'.\n",
      "[Info] Compilando 'images-developed-png-8bit': 30 pares...\n",
      "[OK] Compilado criado em: resultados_etapa4/images-developed-png-8bit/best/best\n",
      "     Use na Etapa 5 com detector='best', matcher='best'.\n",
      "[Info] Compilando 'images-pro': 22 pares...\n",
      "[Aviso] images-pro: par 021-000 sem homografia VÁLIDA entre os métodos — salvando sentinela.\n",
      "[OK] Compilado criado em: resultados_etapa4/images-pro/best/best\n",
      "     Use na Etapa 5 com detector='best', matcher='best'.\n",
      "[Info] Compilando 'images-developed-tiff-8bit': 30 pares...\n",
      "[OK] Compilado criado em: resultados_etapa4/images-developed-tiff-8bit/best/best\n",
      "     Use na Etapa 5 com detector='best', matcher='best'.\n",
      "[Info] Compilando 'images-normal': 61 pares...\n",
      "[Aviso] images-normal: par 060-000 sem homografia VÁLIDA entre os métodos — salvando sentinela.\n",
      "[OK] Compilado criado em: resultados_etapa4/images-normal/best/best\n",
      "     Use na Etapa 5 com detector='best', matcher='best'.\n"
     ]
    }
   ],
   "source": [
    "RAIZ_ETAPA2 = \"resultados_etapa2\"\n",
    "RAIZ_ETAPA3 = \"resultados_etapa3\"\n",
    "RAIZ_ETAPA4 = \"resultados_etapa4\"\n",
    "DETECTORS = ['sift', 'orb', 'akaze']\n",
    "MATCHERS = ['bf', 'flann']\n",
    "\n",
    "compilar_melhores_homografias(\n",
    "    raiz_etapa4=RAIZ_ETAPA4,\n",
    "    raiz_etapa2=RAIZ_ETAPA2,\n",
    "    formatos= [d for d in os.listdir(RAIZ_ETAPA2) if os.path.isdir(os.path.join(RAIZ_ETAPA2, d))],  # todos\n",
    "    detectores=DETECTORS,\n",
    "    matchers=MATCHERS,\n",
    "    nome_detector_out=\"best\",\n",
    "    nome_matcher_out=\"best\",\n",
    "    usar_pares_sequenciais=True,  # pares sequenciais com wrap\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ed35e9",
   "metadata": {},
   "source": [
    "## Etapa bônus: identificação da ordem das imagens com inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b39d2689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "def ciclo_guloso(G, inicio, mais_leve):\n",
    "    \"\"\"\n",
    "    Encontra um ciclo começando e terminando em 'inicio', sempre escolhendo o vizinho de menor (mais_leve=True)\n",
    "    ou maior (mais_leve=False) peso, exceto o pai e já visitados, até retornar ao início ou não haver mais opções.\n",
    "    \"\"\"\n",
    "    caminho = [inicio]\n",
    "    atual = inicio\n",
    "    pai = None\n",
    "    visitados = set([inicio])\n",
    "    while True:\n",
    "        vizinhos = [v for v in G.neighbors(atual) if v != pai and v not in visitados]\n",
    "        # Permite voltar ao início se todos os outros já foram visitados\n",
    "        if not vizinhos and inicio in G.neighbors(atual):\n",
    "            caminho.append(inicio)\n",
    "            print(\"Ciclo completo\")\n",
    "            break\n",
    "        if not vizinhos:\n",
    "            print(\"Sem mais vizinhos disponíveis, ciclo incompleto\")\n",
    "            break\n",
    "        if mais_leve:\n",
    "            proximo = min(vizinhos, key=lambda v: G[atual][v]['weight'])\n",
    "        else:\n",
    "            proximo = max(vizinhos, key=lambda v: G[atual][v]['weight'])\n",
    "        caminho.append(proximo)\n",
    "        visitados.add(proximo)\n",
    "        pai, atual = atual, proximo\n",
    "    return caminho\n",
    "\n",
    "def construir_grafo_de_homografias(caminho_base_etapa4: str, conjunto_imagens: str, detector: str, matcher: str, peso='inliers'):\n",
    "    \"\"\"\n",
    "    Constrói um grafo direcionado onde cada nó é uma imagem e cada aresta é uma homografia entre imagens.\n",
    "    O peso da aresta pode ser 'inliers' (número de inliers, maior é melhor) ou 'rmse' (menor é melhor).\n",
    "    \"\"\"\n",
    "    dir_homogr = os.path.join(caminho_base_etapa4, conjunto_imagens, detector, matcher)\n",
    "    arquivos_homogr = sorted(glob.glob(os.path.join(dir_homogr, \"homogr_*.npz\")))\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    for arq in arquivos_homogr:\n",
    "        _, _, meta = carregar_homogr_npz(arq)\n",
    "        i, j = meta['idx_i'], meta['idx_j']\n",
    "        path_i, path_j = meta['path_i'], meta['path_j']\n",
    "        inliers = meta['inliers']\n",
    "        rmse = meta['rmse_px']\n",
    "        \n",
    "        if peso == 'inliers':\n",
    "            if inliers > 0:\n",
    "                G.add_edge(f\"{path_i}\", f\"{path_j}\", weight=inliers)\n",
    "        elif peso == 'rmse':\n",
    "            if rmse is not None and rmse > 0:\n",
    "                G.add_edge(f\"{path_i}\", f\"{path_j}\", weight=rmse)\n",
    "        else:\n",
    "            raise ValueError(\"Peso deve ser 'inliers' ou 'rmse'.\")\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055fcc18",
   "metadata": {},
   "source": [
    "### Usando número de inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f639c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciclo completo\n",
      "Ciclo guloso começando e terminando em 'images-developed-png-8bit/panorama360raw-1.png': ['images-developed-png-8bit/panorama360raw-1.png', 'images-developed-png-8bit/panorama360raw-2.png', 'images-developed-png-8bit/panorama360raw-3.png', 'images-developed-png-8bit/panorama360raw-4.png', 'images-developed-png-8bit/panorama360raw-5.png', 'images-developed-png-8bit/panorama360raw-6.png', 'images-developed-png-8bit/panorama360raw-7.png', 'images-developed-png-8bit/panorama360raw-8.png', 'images-developed-png-8bit/panorama360raw-9.png', 'images-developed-png-8bit/panorama360raw-10.png', 'images-developed-png-8bit/panorama360raw-11.png', 'images-developed-png-8bit/panorama360raw-12.png', 'images-developed-png-8bit/panorama360raw-13.png', 'images-developed-png-8bit/panorama360raw-14.png', 'images-developed-png-8bit/panorama360raw-15.png', 'images-developed-png-8bit/panorama360raw-16.png', 'images-developed-png-8bit/panorama360raw-17.png', 'images-developed-png-8bit/panorama360raw-18.png', 'images-developed-png-8bit/panorama360raw-19.png', 'images-developed-png-8bit/panorama360raw-20.png', 'images-developed-png-8bit/panorama360raw-21.png', 'images-developed-png-8bit/panorama360raw-22.png', 'images-developed-png-8bit/panorama360raw-23.png', 'images-developed-png-8bit/panorama360raw-24.png', 'images-developed-png-8bit/panorama360raw-25.png', 'images-developed-png-8bit/panorama360raw-26.png', 'images-developed-png-8bit/panorama360raw-27.png', 'images-developed-png-8bit/panorama360raw-28.png', 'images-developed-png-8bit/panorama360raw-29.png', 'images-developed-png-8bit/panorama360raw-30.png', 'images-developed-png-8bit/panorama360raw-1.png']\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso com inliers como peso\n",
    "caminho_base_etapa4 = \"resultados_etapa4\"\n",
    "conjunto_imagens = \"images-developed-png-8bit\"\n",
    "detector = \"sift\"\n",
    "matcher = \"flann\"\n",
    "peso = \"inliers\"\n",
    "\n",
    "G = construir_grafo_de_homografias(caminho_base_etapa4, conjunto_imagens, detector, matcher, peso)\n",
    "\n",
    "# inicio = random.choice(list(G.nodes()))   # Escolha um nó aleatório como início\n",
    "inicio = list(G.nodes())[0]                 # Ou escolha um nó específico conhecido\n",
    "\n",
    "ciclo = ciclo_guloso(G, inicio, mais_leve=False)\n",
    "print(f\"Ciclo guloso começando e terminando em '{inicio}':\", ciclo)\n",
    "\n",
    "# Salva o ciclo em um arquivo json\n",
    "with open(os.path.join(caminho_base_etapa4, conjunto_imagens, detector, matcher, \"ordem.json\"), \"w\") as f:\n",
    "    json.dump(ciclo, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc2b81e",
   "metadata": {},
   "source": [
    "### Usando rmse (não está funcionando bem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d2cf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciclo completo\n",
      "Ciclo guloso começando e terminando em 'images-developed-png-8bit/panorama360raw-11.png': ['images-developed-png-8bit/panorama360raw-11.png', 'images-developed-png-8bit/panorama360raw-4.png', 'images-developed-png-8bit/panorama360raw-16.png', 'images-developed-png-8bit/panorama360raw-21.png', 'images-developed-png-8bit/panorama360raw-10.png', 'images-developed-png-8bit/panorama360raw-23.png', 'images-developed-png-8bit/panorama360raw-17.png', 'images-developed-png-8bit/panorama360raw-6.png', 'images-developed-png-8bit/panorama360raw-28.png', 'images-developed-png-8bit/panorama360raw-9.png', 'images-developed-png-8bit/panorama360raw-22.png', 'images-developed-png-8bit/panorama360raw-8.png', 'images-developed-png-8bit/panorama360raw-18.png', 'images-developed-png-8bit/panorama360raw-12.png', 'images-developed-png-8bit/panorama360raw-5.png', 'images-developed-png-8bit/panorama360raw-24.png', 'images-developed-png-8bit/panorama360raw-13.png', 'images-developed-png-8bit/panorama360raw-1.png', 'images-developed-png-8bit/panorama360raw-14.png', 'images-developed-png-8bit/panorama360raw-25.png', 'images-developed-png-8bit/panorama360raw-2.png', 'images-developed-png-8bit/panorama360raw-27.png', 'images-developed-png-8bit/panorama360raw-20.png', 'images-developed-png-8bit/panorama360raw-7.png', 'images-developed-png-8bit/panorama360raw-19.png', 'images-developed-png-8bit/panorama360raw-26.png', 'images-developed-png-8bit/panorama360raw-15.png', 'images-developed-png-8bit/panorama360raw-3.png', 'images-developed-png-8bit/panorama360raw-30.png', 'images-developed-png-8bit/panorama360raw-29.png', 'images-developed-png-8bit/panorama360raw-11.png']\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso com rmse como peso\n",
    "caminho_base_etapa4 = \"resultados_etapa4\"\n",
    "conjunto_imagens = \"images-developed-png-8bit\"\n",
    "detector = \"sift\"\n",
    "matcher = \"flann\"\n",
    "peso = \"rmse\"\n",
    "\n",
    "G = construir_grafo_de_homografias(caminho_base_etapa4, conjunto_imagens, detector, matcher, peso)\n",
    "\n",
    "# inicio = random.choice(list(G.nodes()))   # Escolha um nó aleatório como início\n",
    "inicio = list(G.nodes())[0]                 # Ou escolha um nó específico conhecido\n",
    "\n",
    "ciclo = ciclo_guloso(G, inicio, mais_leve=True)\n",
    "print(f\"Ciclo guloso começando e terminando em '{inicio}':\", ciclo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
