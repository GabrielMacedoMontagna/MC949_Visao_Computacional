{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa99d41",
   "metadata": {},
   "source": [
    "# Etapa 3: Emparelhamento e Geometria Epipolar\n",
    "\n",
    "**Objetivo:** Utilizar as características da Etapa 2 para estabelecer as relações geométricas entre todos os pares de imagens, preparando os dados para a reconstrução 3D (Structure from Motion).\n",
    "\n",
    "**Pipeline Refinado:**\n",
    "1.  **Carregar Features:** Ler os arquivos `.npz` da Etapa 2.\n",
    "2.  **Emparelhamento Total:** Realizar o matching de características entre **todos os pares possíveis de imagens**.\n",
    "3.  **Filtragem Geométrica Robusta:**\n",
    "    - Aplicar o **Ratio Test**.\n",
    "    - Estimar a **Matriz Fundamental (F)** com **RANSAC**.\n",
    "    - Estimar a **Matriz Intrínseca (K)** a partir dos dados EXIF (ou com heurística melhorada).\n",
    "    - Calcular a **Matriz Essencial (E)** e recuperar a **Pose (R, t)**.\n",
    "    - **Validar a Pose** para rejeitar movimentos de câmera degenerados.\n",
    "    - **Triangular os pontos 3D** e aplicar a **verificação de cheirality** para garantir que os pontos estão na frente de ambas as câmeras.\n",
    "4.  **Salvar Resultados:** Armazenar todas as informações validadas (`inliers`, F, E, R, t, K, pontos 3D) em arquivos `.npz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple\n",
    "from itertools import combinations\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "try:\n",
    "    import pillow_heif\n",
    "    pillow_heif.register_heif_opener()\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba38e7f6",
   "metadata": {},
   "source": [
    "## Funções Auxiliares (Carregamento, Salvamento e Visualização)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "helpers-load-save",
   "metadata": {},
   "outputs": [],
   "source": [
    "def desserializar_keypoints(arr: np.ndarray) -> List[cv2.KeyPoint]:\n",
    "    \"\"\"Reconstrói lista de cv2.KeyPoint a partir do array (N,7).\"\"\"\n",
    "    return [cv2.KeyPoint(x=r[0], y=r[1], size=r[2], angle=r[3], response=r[4], octave=int(r[5]), class_id=int(r[6])) for r in arr]\n",
    "\n",
    "def carregar_features_npz(caminho_npz: str) -> Tuple[List[cv2.KeyPoint], np.ndarray, str]:\n",
    "    \"\"\"Lê um .npz salvo pela Etapa 2.\"\"\"\n",
    "    with np.load(caminho_npz, allow_pickle=True) as data:\n",
    "        kps = desserializar_keypoints(data[\"keypoints\"])\n",
    "        desc = data[\"descriptors\"]\n",
    "        img_path = str(data[\"imagem_absoluta\"])\n",
    "    return kps, desc, img_path\n",
    "\n",
    "def salvar_verificacao_geometrica_npz(caminho_saida: str, i: int, j: int, inlier_matches: List[cv2.DMatch], F: np.ndarray, E: np.ndarray, R: np.ndarray, t: np.ndarray, K: np.ndarray, pontos_3d: np.ndarray):\n",
    "    \"\"\"Salva todos os artefatos da verificação geométrica para um par de imagens.\"\"\"\n",
    "    matches_data = np.array([[m.queryIdx, m.trainIdx, m.distance] for m in inlier_matches], dtype=np.float32)\n",
    "    num_inliers = len(inlier_matches)\n",
    "    np.savez_compressed(\n",
    "        caminho_saida,\n",
    "        idx_i=i, idx_j=j,\n",
    "        matches=matches_data,\n",
    "        num_inliers=num_inliers,\n",
    "        F=F if F is not None else np.eye(3),\n",
    "        E=E if E is not None else np.eye(3),\n",
    "        R=R if R is not None else np.eye(3),\n",
    "        t=t if t is not None else np.zeros((3,1)),\n",
    "        K=K,\n",
    "        pontos_3d=pontos_3d\n",
    "    )\n",
    "\n",
    "def desenhar_matches_custom(img1, kps1, img2, kps2, matches, cor_linha=(255, 0, 255), espessura_linha=2):\n",
    "    \"\"\"Desenha matches entre duas imagens com linhas customizáveis.\"\"\"\n",
    "    h1, w1 = img1.shape[:2]\n",
    "    h2, w2 = img2.shape[:2]\n",
    "    output_img = np.zeros((max(h1, h2), w1 + w2, 3), dtype=np.uint8)\n",
    "    output_img[:h1, :w1] = img1\n",
    "    output_img[:h2, w1:] = img2\n",
    "    if kps1 is None or kps2 is None: return output_img\n",
    "    for m in matches:\n",
    "        pt1 = (int(kps1[m.queryIdx].pt[0]), int(kps1[m.queryIdx].pt[1]))\n",
    "        pt2 = (int(kps2[m.trainIdx].pt[0] + w1), int(kps2[m.trainIdx].pt[1]))\n",
    "        cv2.line(output_img, pt1, pt2, cor_linha, espessura_linha)\n",
    "    return output_img\n",
    "\n",
    "\n",
    "def _pil_to_bgr(pil_img: \"Image.Image\") -> np.ndarray:\n",
    "    \"\"\"Converte PIL.Image para ndarray BGR uint8, aplicando orientação EXIF.\"\"\"\n",
    "    from PIL import ImageOps\n",
    "    pil_img = ImageOps.exif_transpose(pil_img)\n",
    "    if pil_img.mode not in (\"RGB\", \"RGBA\"):\n",
    "        pil_img = pil_img.convert(\"RGB\")\n",
    "    arr = np.array(pil_img)  # RGB(A)\n",
    "    if arr.ndim == 3 and arr.shape[2] == 4:\n",
    "        arr = arr[:, :, :3]  # descarta alpha\n",
    "    return cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "def carregar_imagem(path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Lê imagem em BGR (uint8). Suporta formatos do OpenCV e HEIC/HEIF via Pillow.\n",
    "    \"\"\"\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    if ext in (\".heic\", \".heif\"):\n",
    "        try:\n",
    "            from PIL import Image\n",
    "            pil_img = Image.open(path)\n",
    "            return _pil_to_bgr(pil_img)\n",
    "        except Exception as e:\n",
    "            print(f\"[aviso] Falha ao carregar HEIC com Pillow: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            print(f\"[aviso] não consegui abrir via OpenCV: {path}\")\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904c8940",
   "metadata": {},
   "source": [
    "## Funções de Emparelhamento e Geometria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "helpers-matching-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimar_K_da_imagem(caminho_imagem: str) -> np.ndarray:\n",
    "    \"\"\"Tenta extrair K do EXIF ou usa heurística melhorada.\"\"\"\n",
    "    try:\n",
    "        img = Image.open(caminho_imagem)\n",
    "        exif = img._getexif()\n",
    "        if exif:\n",
    "            focal_length_mm = None\n",
    "            for tag, value in exif.items():\n",
    "                if TAGS.get(tag) == 'FocalLength':\n",
    "                    focal_length_mm = float(value)\n",
    "                    break\n",
    "            if focal_length_mm is not None:\n",
    "                # Simplificação comum: assume sensor de 35mm (36mm de largura)\n",
    "                sensor_width_mm = 36.0\n",
    "                w, h = img.size\n",
    "                fx = fy = (focal_length_mm / sensor_width_mm) * w\n",
    "                cx, cy = w/2, h/2\n",
    "                return np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]], dtype=np.float32)\n",
    "    except Exception:\n",
    "        pass # Silenciosamente falha e usa o fallback\n",
    "    \n",
    "    # Fallback para heurística melhorada se EXIF falhar ou não existir\n",
    "    img_cv = cv2.imread(caminho_imagem)\n",
    "    if img_cv is None: # Se o OpenCV também falhar, usa um K genérico\n",
    "      h, w = 1080, 1920\n",
    "    else:\n",
    "      h, w = img_cv.shape[:2]\n",
    "    fx = fy = max(w, h) * 1.2\n",
    "    return np.array([[fx, 0, w/2], [0, fy, h/2], [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "\n",
    "def criar_matcher(nome_matcher: str, desc_dtype):\n",
    "    \"\"\"Cria um objeto matcher (BF ou FLANN) configurado corretamente.\"\"\"\n",
    "    if nome_matcher.lower() == 'bf':\n",
    "        norm_type = cv2.NORM_L2 if desc_dtype == np.float32 else cv2.NORM_HAMMING\n",
    "        return cv2.BFMatcher(norm_type)\n",
    "    elif nome_matcher.lower() == 'flann':\n",
    "        if desc_dtype == np.float32:\n",
    "            index_params = dict(algorithm=1, trees=5)\n",
    "        else:\n",
    "            index_params = dict(algorithm=6, table_number=6,\n",
    "                                key_size=12, multi_probe_level=1)\n",
    "        search_params = dict(checks=50)\n",
    "        return cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    else:\n",
    "        raise ValueError(f\"Matcher '{nome_matcher}' não reconhecido.\")\n",
    "\n",
    "\n",
    "def filtrar_matches_ratio_test(matches_brutos, ratio=0.75):\n",
    "    \"\"\"Aplica o Ratio Test de David Lowe.\"\"\"\n",
    "    matches_filtrados = []\n",
    "    for match_pair in matches_brutos:\n",
    "        if len(match_pair) == 2:\n",
    "            m, n = match_pair\n",
    "            if m.distance < ratio * n.distance:\n",
    "                matches_filtrados.append(m)\n",
    "    return matches_filtrados\n",
    "\n",
    "def validar_qualidade_pose(R, t, min_angle=1.0, min_translation=1e-3):\n",
    "    \"\"\"Valida se a pose recuperada é geometricamente plausível.\"\"\"\n",
    "    if R is None or t is None: return False\n",
    "    # Verificar se a rotação não é muito pequena\n",
    "    angle = np.arccos(np.clip((np.trace(R) - 1) / 2, -1, 1)) * 180 / np.pi\n",
    "    if angle < min_angle: return False\n",
    "    # Verificar se a translação não é nula\n",
    "    if np.linalg.norm(t) < min_translation: return False\n",
    "    return True\n",
    "\n",
    "def verificar_geometria_par_robusta(kps1, kps2, matches, K, ransac_thresh=0.99, conf=0.999):\n",
    "    \"\"\"Versão mais robusta com validações adicionais.\"\"\"\n",
    "    null_return = None, None, None, None, [], np.zeros((0,3))\n",
    "    if len(matches) < 8: return null_return\n",
    "\n",
    "    pts1 = np.float32([kps1[m.queryIdx].pt for m in matches])\n",
    "    pts2 = np.float32([kps2[m.trainIdx].pt for m in matches])\n",
    "\n",
    "    F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC, ransac_thresh, conf)\n",
    "    if F is None or mask is None: return null_return\n",
    "\n",
    "    inlier_mask = mask.ravel().astype(bool)\n",
    "    inlier_matches = [m for i, m in enumerate(matches) if inlier_mask[i]]\n",
    "    if len(inlier_matches) < 8: return null_return\n",
    "\n",
    "    pts1_inliers = pts1[inlier_mask]\n",
    "    pts2_inliers = pts2[inlier_mask]\n",
    "    \n",
    "    E = K.T @ F @ K\n",
    "    _, R, t, _ = cv2.recoverPose(E, pts1_inliers, pts2_inliers, K)\n",
    "\n",
    "    if not validar_qualidade_pose(R, t): return F, E, None, None, inlier_matches, np.zeros((0,3))\n",
    "\n",
    "    proj_mat1 = K @ np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "    proj_mat2 = K @ np.hstack((R, t))\n",
    "    pontos_4d_hom = cv2.triangulatePoints(proj_mat1, proj_mat2, pts1_inliers.T, pts2_inliers.T)\n",
    "    pontos_3d_hom = pontos_4d_hom / pontos_4d_hom[3]\n",
    "\n",
    "    # Verificação de Cheirality\n",
    "    pontos_3d_cam1 = pontos_3d_hom[:3].T\n",
    "    pontos_3d_cam2 = (R @ pontos_3d_cam1.T + t).T\n",
    "    cheirality_mask = (pontos_3d_cam1[:, 2] > 0) & (pontos_3d_cam2[:, 2] > 0)\n",
    "\n",
    "    # Filtra os resultados com base na cheirality\n",
    "    inlier_matches = [m for i, m in enumerate(inlier_matches) if cheirality_mask[i]]\n",
    "    pontos_3d_validos = pontos_3d_cam1[cheirality_mask]\n",
    "\n",
    "    if len(inlier_matches) < 8: return F, E, R, t, [], np.zeros((0,3))\n",
    "\n",
    "    return F, E, R, t, inlier_matches, pontos_3d_validos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1942c7a7",
   "metadata": {},
   "source": [
    "## Nota sobre Eficiência e Escala\n",
    "\n",
    "A abordagem de emparelhar \"todos com todos\" (`all-pairs`) garante que nenhuma conexão visual seja perdida, o que é ideal para a máxima robustez. Contudo, sua complexidade é quadrática (O(n²)), o que pode tornar o processamento muito lento para conjuntos com centenas de imagens. \n",
    "\n",
    "Para este projeto (40-120 imagens), esta abordagem é viável. Em um cenário de produção, seriam necessárias otimizações como:\n",
    "- **Pré-filtragem de Pares:** Usar técnicas mais baratas (como similaridade de histograma ou *bag of visual words*) para descartar pares de imagens que claramente não têm sobreposição, antes de executar o custoso matching de features.\n",
    "- **Matching Sequencial com Janela:** Para vídeos ou capturas em sequência, limitar o matching a uma janela de imagens próximas (ex: cada imagem com as 5 seguintes).\n",
    "- **Paralelização:** Distribuir o processamento dos pares entre múltiplos núcleos de CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "main-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisar_geometria_conjunto(caminho_base_etapa2: str, matchers_a_usar: List[str]):\n",
    "    \"\"\"Pipeline da Etapa 3: Carrega features, realiza matching, verifica geometria e salva os resultados.\"\"\"\n",
    "    nome_conjunto = os.path.basename(caminho_base_etapa2)\n",
    "    print(f\"\\n{'='*65}\\nAnalisando Geometria para o conjunto: '{nome_conjunto}'\\n{'='*65}\")\n",
    "    \n",
    "    detectores = [d for d in os.listdir(caminho_base_etapa2) if os.path.isdir(os.path.join(caminho_base_etapa2, d)) and d.lower() != 'akaze']\n",
    "    for nome_detector in detectores:\n",
    "        print(f\"\\n--- Detector: {nome_detector.upper()} ---\")\n",
    "        caminho_detector_etapa2 = os.path.join(caminho_base_etapa2, nome_detector)\n",
    "        arquivos_npz = sorted(glob.glob(os.path.join(caminho_detector_etapa2, \"*_features.npz\")))\n",
    "        if len(arquivos_npz) < 2: continue\n",
    "\n",
    "        pares_indices = list(combinations(range(len(arquivos_npz)), 2))\n",
    "\n",
    "        # Estima K para cada imagem uma vez para economizar tempo\n",
    "        matrizes_K = [estimar_K_da_imagem(carregar_features_npz(npz)[2]) for npz in arquivos_npz]\n",
    "\n",
    "        for nome_matcher in matchers_a_usar:\n",
    "            print(f\"  - Matcher: {nome_matcher.upper()}\")\n",
    "            dir_saida = os.path.join(\"resultados_etapa3\", nome_conjunto, nome_detector, nome_matcher)\n",
    "            os.makedirs(dir_saida, exist_ok=True)\n",
    "\n",
    "            # Contadores para estatísticas\n",
    "            total_inliers = 0\n",
    "            pares_validos = 0\n",
    "            total_pares = len(pares_indices)\n",
    "\n",
    "            for i, j in pares_indices:\n",
    "                kps1, desc1, path1 = carregar_features_npz(arquivos_npz[i])\n",
    "                kps2, desc2, path2 = carregar_features_npz(arquivos_npz[j])\n",
    "                \n",
    "                if not kps1 or not kps2 or desc1 is None or desc2 is None or desc1.shape[0] == 0 or desc2.shape[0] == 0: continue\n",
    "                \n",
    "                matcher = criar_matcher(nome_matcher, desc1.dtype)\n",
    "                matches_brutos = matcher.knnMatch(desc1, desc2, k=2)\n",
    "                matches_filtrados = filtrar_matches_ratio_test(matches_brutos)\n",
    "\n",
    "                K1 = matrizes_K[i] # Usa a matriz K da primeira imagem do par\n",
    "                F, E, R, t, inliers, pts3d = verificar_geometria_par_robusta(kps1, kps2, matches_filtrados, K1)\n",
    "                if len(inliers) != 0:\n",
    "                    # Atualizar contadores (sem print individual)\n",
    "                    pares_validos += 1\n",
    "                    total_inliers += len(inliers)\n",
    "\n",
    "                salvar_verificacao_geometrica_npz(os.path.join(dir_saida, f\"geometria_{i:03d}_{j:03d}.npz\"), i, j, inliers, F, E, R, t, K1, pts3d)\n",
    "                \n",
    "                if len(inliers) > 20:\n",
    "                    # Corrigir os caminhos das imagens incluindo o nome do dataset\n",
    "                    img1_path = os.path.join(\n",
    "                        \"resultados_etapa2\", nome_conjunto, nome_detector, f\"img_{i:03d}_keypoints.jpg\")\n",
    "                    img2_path = os.path.join(\n",
    "                        \"resultados_etapa2\", nome_conjunto, nome_detector, f\"img_{j:03d}_keypoints.jpg\")\n",
    "\n",
    "                    # Verificar se os arquivos existem antes de tentar carregar\n",
    "                    if os.path.exists(img1_path) and os.path.exists(img2_path):\n",
    "                        img1 = cv2.imread(img1_path)\n",
    "                        img2 = cv2.imread(img2_path)\n",
    "\n",
    "                        if img1 is not None and img2 is not None:\n",
    "                            preview_matches = desenhar_matches_custom(\n",
    "                                img1, kps1, img2, kps2, inliers)\n",
    "                            cv2.imwrite(os.path.join(\n",
    "                                dir_saida, f\"preview_inliers_{i:03d}_{j:03d}.jpg\"), preview_matches)\n",
    "            \n",
    "            # Resumo estatístico por matcher\n",
    "            media_inliers = total_inliers / pares_validos if pares_validos > 0 else 0\n",
    "            print(f\"    Resumo {nome_matcher.upper()}: {pares_validos}/{total_pares} pares válidos, \"\n",
    "                  f\"{total_inliers} inliers totais, média {media_inliers:.1f} inliers/par\")\n",
    "        \n",
    "        print(f\"--- Detector {nome_detector.upper()} concluído ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f285a1de",
   "metadata": {},
   "source": [
    "## Execução do Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "execution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "Analisando Geometria para o conjunto: 'Imagens4'\n",
      "=================================================================\n",
      "\n",
      "--- Detector: ORB ---\n",
      "  - Matcher: BF\n",
      "  - Matcher: BF\n",
      "    Resumo BF: 1459/4186 pares válidos, 32122 inliers totais, média 22.0 inliers/par\n",
      "--- Detector ORB concluído ---\n",
      "    Resumo BF: 1459/4186 pares válidos, 32122 inliers totais, média 22.0 inliers/par\n",
      "--- Detector ORB concluído ---\n"
     ]
    }
   ],
   "source": [
    "RAIZ_ETAPA2 = \"resultados_etapa2\"\n",
    "CONJUNTOS = ['Imagens4']\n",
    "MATCHERS = ['bf'] # 'flann'\n",
    "\n",
    "for conjunto in CONJUNTOS:\n",
    "    caminho_do_conjunto = f\"{RAIZ_ETAPA2}/{conjunto}\"\n",
    "    analisar_geometria_conjunto(caminho_do_conjunto, MATCHERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4504d1",
   "metadata": {},
   "source": [
    "## Geração do Relatório Comparativo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "report",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gerando relatório comparativo final da Etapa 3...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'resultados_etapa3'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTabela resumo salva em: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaminho_saida_final\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Execução\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[43mgerar_relatorio_final_etapa3\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresultados_etapa3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mgerar_relatorio_final_etapa3\u001b[39m\u001b[34m(raiz_resultados)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mGerando relatório comparativo final da Etapa 3...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m dados_tabela = []\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m nome_conjunto \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraiz_resultados\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[32m      7\u001b[39m     caminho_conjunto = os.path.join(raiz_resultados, nome_conjunto)\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isdir(caminho_conjunto):\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'resultados_etapa3'"
     ]
    }
   ],
   "source": [
    "def gerar_relatorio_final_etapa3(raiz_resultados: str):\n",
    "    \"\"\"Gera uma tabela CSV comparando a média de inliers geométricos por combinação.\"\"\"\n",
    "    print(\"\\nGerando relatório comparativo final da Etapa 3...\")\n",
    "    dados_tabela = []\n",
    "\n",
    "    for nome_conjunto in sorted(os.listdir(raiz_resultados)):\n",
    "        caminho_conjunto = os.path.join(raiz_resultados, nome_conjunto)\n",
    "        if not os.path.isdir(caminho_conjunto):\n",
    "            continue\n",
    "        for nome_detector in sorted(os.listdir(caminho_conjunto)):\n",
    "            caminho_detector = os.path.join(caminho_conjunto, nome_detector)\n",
    "            if not os.path.isdir(caminho_detector):\n",
    "                continue\n",
    "            for nome_matcher in sorted(os.listdir(caminho_detector)):\n",
    "                caminho_matcher = os.path.join(caminho_detector, nome_matcher)\n",
    "                if not os.path.isdir(caminho_matcher):\n",
    "                    continue\n",
    "\n",
    "                arquivos_geometria_npz = glob.glob(\n",
    "                    os.path.join(caminho_matcher, \"geometria_*.npz\"))\n",
    "                if not arquivos_geometria_npz:\n",
    "                    media_inliers = 0.0\n",
    "                else:\n",
    "                    contagens = []\n",
    "                    for npz in arquivos_geometria_npz:\n",
    "                        with np.load(npz) as data:\n",
    "                            contagens.append(data['matches'].shape[0])\n",
    "                    media_inliers = np.mean(contagens)\n",
    "\n",
    "                dados_tabela.append({\n",
    "                    \"conjunto\": nome_conjunto,\n",
    "                    \"detector\": nome_detector,\n",
    "                    \"matcher\": nome_matcher,\n",
    "                    \"media_inliers_geometricos_por_par\": media_inliers\n",
    "                })\n",
    "\n",
    "    if not dados_tabela:\n",
    "        print(\"Nenhum dado encontrado para gerar o relatório.\")\n",
    "        return\n",
    "\n",
    "    df_final = pd.DataFrame(dados_tabela)\n",
    "    df_final['media_inliers_geometricos_por_par'] = df_final['media_inliers_geometricos_por_par'].map(\n",
    "        '{:,.2f}'.format)\n",
    "\n",
    "    print(f\"\\n{'='*80}\\nRELATÓRIO COMPARATIVO FINAL - ETAPA 3\\n{'='*80}\")\n",
    "    print(df_final.to_string(index=False))\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    caminho_saida_final = os.path.join(\n",
    "        raiz_resultados, \"relatorio_comparativo_geometria.csv\")\n",
    "    df_final.to_csv(caminho_saida_final, index=False, sep=';')\n",
    "    print(f\"\\nTabela resumo salva em: '{caminho_saida_final}'\")\n",
    "\n",
    "\n",
    "# Execução\n",
    "gerar_relatorio_final_etapa3(\"resultados_etapa3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_mc949",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
